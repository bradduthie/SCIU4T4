<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Measures of spread | Statistical Techniques for Biological and Environmental Sciences</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Measures of spread | Statistical Techniques for Biological and Environmental Sciences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="bradduthie/statistical_techniques" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Measures of spread | Statistical Techniques for Biological and Environmental Sciences" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Brad Duthie" />


<meta name="date" content="2022-12-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chapter_11.html"/>
<link rel="next" href="Chapter_13.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { font-weight: bold; } /* Alert */
code span.an { font-style: italic; } /* Annotation */
code span.cf { font-weight: bold; } /* ControlFlow */
code span.co { font-style: italic; } /* Comment */
code span.cv { font-style: italic; } /* CommentVar */
code span.do { font-style: italic; } /* Documentation */
code span.dt { text-decoration: underline; } /* DataType */
code span.er { font-weight: bold; } /* Error */
code span.in { font-style: italic; } /* Information */
code span.kw { font-weight: bold; } /* Keyword */
code span.pp { font-weight: bold; } /* Preprocessor */
code span.wa { font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Techniques</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-is-statistics"><i class="fa fa-check"></i>What is statistics?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this-module-is-important"><i class="fa fa-check"></i>Why this module is important</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#teaching-overview"><i class="fa fa-check"></i>Teaching overview</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#assessment-overview"><i class="fa fa-check"></i>Assessment overview</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#test-1f"><i class="fa fa-check"></i>Test 1F</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#test-1s"><i class="fa fa-check"></i>Test 1S</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#test-2s"><i class="fa fa-check"></i>Test 2S</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mock-exam"><i class="fa fa-check"></i>Mock Exam</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#exam"><i class="fa fa-check"></i>Exam</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#jamovi-statistical-software"><i class="fa fa-check"></i>Jamovi statistical software</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#textbooks"><i class="fa fa-check"></i>Textbooks</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#canvas"><i class="fa fa-check"></i>Canvas</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#timetable"><i class="fa fa-check"></i>Timetable</a></li>
</ul></li>
<li class="part"><span><b>I Background mathematics and data organisation</b></span></li>
<li class="chapter" data-level="" data-path="week-1-overview.html"><a href="week-1-overview.html"><i class="fa fa-check"></i>Week 1 Overview</a></li>
<li class="chapter" data-level="1" data-path="Chapter_1.html"><a href="Chapter_1.html"><i class="fa fa-check"></i><b>1</b> Background mathematics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="Chapter_1.html"><a href="Chapter_1.html#numbers-and-operations"><i class="fa fa-check"></i><b>1.1</b> Numbers and operations</a></li>
<li class="chapter" data-level="1.2" data-path="Chapter_1.html"><a href="Chapter_1.html#logarithms"><i class="fa fa-check"></i><b>1.2</b> Logarithms</a></li>
<li class="chapter" data-level="1.3" data-path="Chapter_1.html"><a href="Chapter_1.html#order-of-operations"><i class="fa fa-check"></i><b>1.3</b> Order of operations</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chapter_2.html"><a href="Chapter_2.html"><i class="fa fa-check"></i><b>2</b> Data organisation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="Chapter_2.html"><a href="Chapter_2.html#tidy-data"><i class="fa fa-check"></i><b>2.1</b> Tidy data</a></li>
<li class="chapter" data-level="2.2" data-path="Chapter_2.html"><a href="Chapter_2.html#data-files"><i class="fa fa-check"></i><b>2.2</b> Data files</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chapter_3.html"><a href="Chapter_3.html"><i class="fa fa-check"></i><b>3</b> <em>Practical</em>: Preparing data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-1"><i class="fa fa-check"></i><b>3.1</b> Exercise 1</a></li>
<li class="chapter" data-level="3.2" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-2"><i class="fa fa-check"></i><b>3.2</b> Exercise 2</a></li>
<li class="chapter" data-level="3.3" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-3"><i class="fa fa-check"></i><b>3.3</b> Exercise 3</a></li>
<li class="chapter" data-level="3.4" data-path="Chapter_3.html"><a href="Chapter_3.html#exercise-4"><i class="fa fa-check"></i><b>3.4</b> Exercise 4</a></li>
<li class="chapter" data-level="3.5" data-path="Chapter_3.html"><a href="Chapter_3.html#summary"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>II Statistical concepts</b></span></li>
<li class="chapter" data-level="" data-path="week-2-overview.html"><a href="week-2-overview.html"><i class="fa fa-check"></i>Week 2 Overview</a></li>
<li class="chapter" data-level="4" data-path="Chapter_4.html"><a href="Chapter_4.html"><i class="fa fa-check"></i><b>4</b> Populations and samples</a></li>
<li class="chapter" data-level="5" data-path="Chapter_5.html"><a href="Chapter_5.html"><i class="fa fa-check"></i><b>5</b> Types of variables</a></li>
<li class="chapter" data-level="6" data-path="Chapter_6.html"><a href="Chapter_6.html"><i class="fa fa-check"></i><b>6</b> Accuracy, precision, and units</a>
<ul>
<li class="chapter" data-level="6.1" data-path="Chapter_6.html"><a href="Chapter_6.html#accuracy"><i class="fa fa-check"></i><b>6.1</b> Accuracy</a></li>
<li class="chapter" data-level="6.2" data-path="Chapter_6.html"><a href="Chapter_6.html#precision"><i class="fa fa-check"></i><b>6.2</b> Precision</a></li>
<li class="chapter" data-level="6.3" data-path="Chapter_6.html"><a href="Chapter_6.html#systems-of-units"><i class="fa fa-check"></i><b>6.3</b> Systems of units</a></li>
<li class="chapter" data-level="6.4" data-path="Chapter_6.html"><a href="Chapter_6.html#other-examples-of-units"><i class="fa fa-check"></i><b>6.4</b> Other examples of units</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="Chapter_6.html"><a href="Chapter_6.html#units-of-density"><i class="fa fa-check"></i><b>6.4.1</b> Units of density</a></li>
<li class="chapter" data-level="6.4.2" data-path="Chapter_6.html"><a href="Chapter_6.html#mass-of-metal-discharged-from-a-catchment"><i class="fa fa-check"></i><b>6.4.2</b> Mass of metal discharged from a catchment</a></li>
<li class="chapter" data-level="6.4.3" data-path="Chapter_6.html"><a href="Chapter_6.html#soil-carbon-inventories"><i class="fa fa-check"></i><b>6.4.3</b> Soil carbon inventories</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chapter_7.html"><a href="Chapter_7.html"><i class="fa fa-check"></i><b>7</b> Uncertainty propogation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="Chapter_7.html"><a href="Chapter_7.html#adding-or-subtracting-errors"><i class="fa fa-check"></i><b>7.1</b> Adding or subtracting errors</a></li>
<li class="chapter" data-level="7.2" data-path="Chapter_7.html"><a href="Chapter_7.html#multiplying-or-dividing-errors"><i class="fa fa-check"></i><b>7.2</b> Multiplying or dividing errors</a></li>
<li class="chapter" data-level="7.3" data-path="Chapter_7.html"><a href="Chapter_7.html#applying-formulas-for-combining-errors"><i class="fa fa-check"></i><b>7.3</b> Applying formulas for combining errors</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chapter_8.html"><a href="Chapter_8.html"><i class="fa fa-check"></i><b>8</b> <em>Practical</em>. Introduction to Jamovi</a>
<ul>
<li class="chapter" data-level="8.1" data-path="Chapter_8.html"><a href="Chapter_8.html#summary_statistics_02"><i class="fa fa-check"></i><b>8.1</b> Exercise for summary statistics</a></li>
<li class="chapter" data-level="8.2" data-path="Chapter_8.html"><a href="Chapter_8.html#transforming_variables_02"><i class="fa fa-check"></i><b>8.2</b> Exercise on transforming variables</a></li>
<li class="chapter" data-level="8.3" data-path="Chapter_8.html"><a href="Chapter_8.html#computing_variables_02"><i class="fa fa-check"></i><b>8.3</b> Exercise on computing variables</a></li>
</ul></li>
<li class="part"><span><b>III Summary statistics</b></span></li>
<li class="chapter" data-level="" data-path="week-3-overview.html"><a href="week-3-overview.html"><i class="fa fa-check"></i>Week 3 Overview</a></li>
<li class="chapter" data-level="9" data-path="Chapter_9.html"><a href="Chapter_9.html"><i class="fa fa-check"></i><b>9</b> Decimal places, significant figures, and rounding</a>
<ul>
<li class="chapter" data-level="9.1" data-path="Chapter_9.html"><a href="Chapter_9.html#decimal-places-and-significant-figures"><i class="fa fa-check"></i><b>9.1</b> Decimal places and significant figures</a></li>
<li class="chapter" data-level="9.2" data-path="Chapter_9.html"><a href="Chapter_9.html#rounding"><i class="fa fa-check"></i><b>9.2</b> Rounding</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chapter_10.html"><a href="Chapter_10.html"><i class="fa fa-check"></i><b>10</b> Graphs</a>
<ul>
<li class="chapter" data-level="10.1" data-path="Chapter_10.html"><a href="Chapter_10.html#histograms"><i class="fa fa-check"></i><b>10.1</b> Histograms</a></li>
<li class="chapter" data-level="10.2" data-path="Chapter_10.html"><a href="Chapter_10.html#barplots-and-pie-charts"><i class="fa fa-check"></i><b>10.2</b> Barplots and pie charts</a></li>
<li class="chapter" data-level="10.3" data-path="Chapter_10.html"><a href="Chapter_10.html#box-whisker-plots"><i class="fa fa-check"></i><b>10.3</b> Box-whisker plots</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chapter_11.html"><a href="Chapter_11.html"><i class="fa fa-check"></i><b>11</b> Measures of central tendency</a>
<ul>
<li class="chapter" data-level="11.1" data-path="Chapter_11.html"><a href="Chapter_11.html#the-mean"><i class="fa fa-check"></i><b>11.1</b> The mean</a></li>
<li class="chapter" data-level="11.2" data-path="Chapter_11.html"><a href="Chapter_11.html#the-mode"><i class="fa fa-check"></i><b>11.2</b> The mode</a></li>
<li class="chapter" data-level="11.3" data-path="Chapter_11.html"><a href="Chapter_11.html#the-median-and-quantiles"><i class="fa fa-check"></i><b>11.3</b> The median and quantiles</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chapter_12.html"><a href="Chapter_12.html"><i class="fa fa-check"></i><b>12</b> Measures of spread</a>
<ul>
<li class="chapter" data-level="12.1" data-path="Chapter_12.html"><a href="Chapter_12.html#the-range"><i class="fa fa-check"></i><b>12.1</b> The range</a></li>
<li class="chapter" data-level="12.2" data-path="Chapter_12.html"><a href="Chapter_12.html#the-inter-quartile-range"><i class="fa fa-check"></i><b>12.2</b> The inter-quartile range</a></li>
<li class="chapter" data-level="12.3" data-path="Chapter_12.html"><a href="Chapter_12.html#the-variance"><i class="fa fa-check"></i><b>12.3</b> The variance</a></li>
<li class="chapter" data-level="12.4" data-path="Chapter_12.html"><a href="Chapter_12.html#the-standard-deviation"><i class="fa fa-check"></i><b>12.4</b> The standard deviation</a></li>
<li class="chapter" data-level="12.5" data-path="Chapter_12.html"><a href="Chapter_12.html#the-coefficient-of-variation"><i class="fa fa-check"></i><b>12.5</b> The coefficient of variation</a></li>
<li class="chapter" data-level="12.6" data-path="Chapter_12.html"><a href="Chapter_12.html#the-standard-error"><i class="fa fa-check"></i><b>12.6</b> The standard error</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chapter_13.html"><a href="Chapter_13.html"><i class="fa fa-check"></i><b>13</b> <em>Practical</em>. Plotting and statistical summaries in Jamovi</a>
<ul>
<li class="chapter" data-level="13.1" data-path="Chapter_13.html"><a href="Chapter_13.html#reorganise-the-dataset-into-a-tidy-format"><i class="fa fa-check"></i><b>13.1</b> Reorganise the dataset into a tidy format</a></li>
<li class="chapter" data-level="13.2" data-path="Chapter_13.html"><a href="Chapter_13.html#histograms-and-box-whisker-plots"><i class="fa fa-check"></i><b>13.2</b> Histograms and box-whisker plots</a></li>
<li class="chapter" data-level="13.3" data-path="Chapter_13.html"><a href="Chapter_13.html#calculate-summary-statistics"><i class="fa fa-check"></i><b>13.3</b> Calculate summary statistics</a></li>
<li class="chapter" data-level="13.4" data-path="Chapter_13.html"><a href="Chapter_13.html#reporting-decimals-and-significant-figures"><i class="fa fa-check"></i><b>13.4</b> Reporting decimals and significant figures</a></li>
<li class="chapter" data-level="13.5" data-path="Chapter_13.html"><a href="Chapter_13.html#comparing-across-sites"><i class="fa fa-check"></i><b>13.5</b> Comparing across sites</a></li>
</ul></li>
<li class="part"><span><b>IV Probability models and the Central Limit Theorem</b></span></li>
<li class="chapter" data-level="" data-path="week-4-overview.html"><a href="week-4-overview.html"><i class="fa fa-check"></i>Week 4 Overview</a></li>
<li class="chapter" data-level="14" data-path="introduction-to-probability-models.html"><a href="introduction-to-probability-models.html"><i class="fa fa-check"></i><b>14</b> Introduction to probability models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="introduction-to-probability-models.html"><a href="introduction-to-probability-models.html#an-instructive-example"><i class="fa fa-check"></i><b>14.1</b> An instructive example</a></li>
<li class="chapter" data-level="14.2" data-path="introduction-to-probability-models.html"><a href="introduction-to-probability-models.html#biological-applications"><i class="fa fa-check"></i><b>14.2</b> Biological applications</a></li>
<li class="chapter" data-level="14.3" data-path="introduction-to-probability-models.html"><a href="introduction-to-probability-models.html#sampling-with-and-without-replacement"><i class="fa fa-check"></i><b>14.3</b> Sampling with and without replacement</a></li>
<li class="chapter" data-level="14.4" data-path="introduction-to-probability-models.html"><a href="introduction-to-probability-models.html#probability-distributions"><i class="fa fa-check"></i><b>14.4</b> Probability distributions</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="introduction-to-probability-models.html"><a href="introduction-to-probability-models.html#binomial-distribution"><i class="fa fa-check"></i><b>14.4.1</b> Binomial distribution</a></li>
<li class="chapter" data-level="14.4.2" data-path="introduction-to-probability-models.html"><a href="introduction-to-probability-models.html#poisson-distribution"><i class="fa fa-check"></i><b>14.4.2</b> Poisson distribution</a></li>
<li class="chapter" data-level="14.4.3" data-path="introduction-to-probability-models.html"><a href="introduction-to-probability-models.html#uniform-distribution"><i class="fa fa-check"></i><b>14.4.3</b> Uniform distribution</a></li>
<li class="chapter" data-level="14.4.4" data-path="introduction-to-probability-models.html"><a href="introduction-to-probability-models.html#normal-distribution"><i class="fa fa-check"></i><b>14.4.4</b> Normal distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="the-central-limit-theorem-clt.html"><a href="the-central-limit-theorem-clt.html"><i class="fa fa-check"></i><b>15</b> The Central Limit Theorem (CLT)</a>
<ul>
<li class="chapter" data-level="15.1" data-path="the-central-limit-theorem-clt.html"><a href="the-central-limit-theorem-clt.html#examples-of-the-clt-in-action"><i class="fa fa-check"></i><b>15.1</b> Examples of the CLT in action</a></li>
<li class="chapter" data-level="15.2" data-path="the-central-limit-theorem-clt.html"><a href="the-central-limit-theorem-clt.html#the-standard-normal-distribution"><i class="fa fa-check"></i><b>15.2</b> The standard normal distribution</a></li>
<li class="chapter" data-level="15.3" data-path="the-central-limit-theorem-clt.html"><a href="the-central-limit-theorem-clt.html#what-are-z-scores"><i class="fa fa-check"></i><b>15.3</b> What are z-scores?</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="practical.-probability-and-simulation.html"><a href="practical.-probability-and-simulation.html"><i class="fa fa-check"></i><b>16</b> <em>Practical</em>. Probability and simulation</a>
<ul>
<li class="chapter" data-level="16.1" data-path="practical.-probability-and-simulation.html"><a href="practical.-probability-and-simulation.html#probabilities-from-a-dataset"><i class="fa fa-check"></i><b>16.1</b> Probabilities from a dataset</a></li>
<li class="chapter" data-level="16.2" data-path="practical.-probability-and-simulation.html"><a href="practical.-probability-and-simulation.html#probabilities-from-a-normal-distribution"><i class="fa fa-check"></i><b>16.2</b> Probabilities from a normal distribution</a></li>
<li class="chapter" data-level="16.3" data-path="practical.-probability-and-simulation.html"><a href="practical.-probability-and-simulation.html#central-limit-theorem"><i class="fa fa-check"></i><b>16.3</b> Central limit theorem</a></li>
</ul></li>
<li class="part"><span><b>V Statistical inference</b></span></li>
<li class="chapter" data-level="" data-path="week-5-overview.html"><a href="week-5-overview.html"><i class="fa fa-check"></i>Week 5 Overview</a></li>
<li class="chapter" data-level="17" data-path="sample-statistics-and-population-parameters.html"><a href="sample-statistics-and-population-parameters.html"><i class="fa fa-check"></i><b>17</b> Sample statistics and population parameters</a></li>
<li class="chapter" data-level="18" data-path="standard-normal-distribution.html"><a href="standard-normal-distribution.html"><i class="fa fa-check"></i><b>18</b> Standard Normal Distribution</a></li>
<li class="chapter" data-level="19" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>19</b> Confidence intervals</a></li>
<li class="chapter" data-level="20" data-path="the-t-interval.html"><a href="the-t-interval.html"><i class="fa fa-check"></i><b>20</b> The t-interval</a></li>
<li class="chapter" data-level="21" data-path="practical.-z--and-t--intervals.html"><a href="practical.-z--and-t--intervals.html"><i class="fa fa-check"></i><b>21</b> <em>Practical</em>. z- and t- intervals</a>
<ul>
<li class="chapter" data-level="21.1" data-path="practical.-z--and-t--intervals.html"><a href="practical.-z--and-t--intervals.html#example-constructing-confidence-intervals"><i class="fa fa-check"></i><b>21.1</b> Example constructing confidence intervals</a></li>
<li class="chapter" data-level="21.2" data-path="practical.-z--and-t--intervals.html"><a href="practical.-z--and-t--intervals.html#confidence-interval-for-different-levels-t--and-z-"><i class="fa fa-check"></i><b>21.2</b> Confidence interval for different levels (t- and z-)</a></li>
<li class="chapter" data-level="21.3" data-path="practical.-z--and-t--intervals.html"><a href="practical.-z--and-t--intervals.html#proportion-confidence-intervals"><i class="fa fa-check"></i><b>21.3</b> Proportion confidence intervals</a></li>
<li class="chapter" data-level="21.4" data-path="practical.-z--and-t--intervals.html"><a href="practical.-z--and-t--intervals.html#another-confidence-interval-example"><i class="fa fa-check"></i><b>21.4</b> Another confidence interval example?</a></li>
</ul></li>
<li class="part"><span><b>VI Hypothesis testing</b></span></li>
<li class="chapter" data-level="" data-path="week-6-overview.html"><a href="week-6-overview.html"><i class="fa fa-check"></i>Week 6 Overview</a></li>
<li class="chapter" data-level="22" data-path="what-is-hypothesis-testing.html"><a href="what-is-hypothesis-testing.html"><i class="fa fa-check"></i><b>22</b> What is hypothesis testing?</a></li>
<li class="chapter" data-level="23" data-path="making-and-using-hypotheses-and-types-of-tests.html"><a href="making-and-using-hypotheses-and-types-of-tests.html"><i class="fa fa-check"></i><b>23</b> Making and using hypotheses and types of tests</a></li>
<li class="chapter" data-level="24" data-path="an-example-of-hypothesis-testing.html"><a href="an-example-of-hypothesis-testing.html"><i class="fa fa-check"></i><b>24</b> An example of hypothesis testing</a></li>
<li class="chapter" data-level="25" data-path="hypothesis-testing-and-confidence-intervals.html"><a href="hypothesis-testing-and-confidence-intervals.html"><i class="fa fa-check"></i><b>25</b> Hypothesis testing and confidence intervals</a></li>
<li class="chapter" data-level="26" data-path="student-t-distribution-and-one-sample-t-test.html"><a href="student-t-distribution-and-one-sample-t-test.html"><i class="fa fa-check"></i><b>26</b> Student t-distribution and one sample t-test</a></li>
<li class="chapter" data-level="27" data-path="another-example-of-a-one-sample-t-test.html"><a href="another-example-of-a-one-sample-t-test.html"><i class="fa fa-check"></i><b>27</b> Another example of a one sample t-test</a></li>
<li class="chapter" data-level="28" data-path="independent-t-test.html"><a href="independent-t-test.html"><i class="fa fa-check"></i><b>28</b> Independent t-test</a></li>
<li class="chapter" data-level="29" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html"><i class="fa fa-check"></i><b>29</b> Paired sample t-test</a></li>
<li class="chapter" data-level="30" data-path="violations-of-assumptions.html"><a href="violations-of-assumptions.html"><i class="fa fa-check"></i><b>30</b> Violations of assumptions</a></li>
<li class="chapter" data-level="31" data-path="non-parametric-tests-and-what-these-are..html"><a href="non-parametric-tests-and-what-these-are..html"><i class="fa fa-check"></i><b>31</b> Non-parametric tests, and what these are.</a></li>
<li class="chapter" data-level="32" data-path="practical.-hypothesis-testing-and-t-tests.html"><a href="practical.-hypothesis-testing-and-t-tests.html"><i class="fa fa-check"></i><b>32</b> <em>Practical</em>. Hypothesis testing and t-tests</a>
<ul>
<li class="chapter" data-level="32.1" data-path="practical.-hypothesis-testing-and-t-tests.html"><a href="practical.-hypothesis-testing-and-t-tests.html#exercise-on-a-simple-one-sample-t-test"><i class="fa fa-check"></i><b>32.1</b> Exercise on a simple one sample t-test</a></li>
<li class="chapter" data-level="32.2" data-path="practical.-hypothesis-testing-and-t-tests.html"><a href="practical.-hypothesis-testing-and-t-tests.html#exercise-on-an-independent-sample-t-test"><i class="fa fa-check"></i><b>32.2</b> Exercise on an independent sample t-test</a></li>
<li class="chapter" data-level="32.3" data-path="practical.-hypothesis-testing-and-t-tests.html"><a href="practical.-hypothesis-testing-and-t-tests.html#exercise-involving-multiple-comparisons"><i class="fa fa-check"></i><b>32.3</b> Exercise involving multiple comparisons</a></li>
<li class="chapter" data-level="32.4" data-path="practical.-hypothesis-testing-and-t-tests.html"><a href="practical.-hypothesis-testing-and-t-tests.html#exercise-with-non-parametric"><i class="fa fa-check"></i><b>32.4</b> Exercise with non-parametric</a></li>
<li class="chapter" data-level="32.5" data-path="practical.-hypothesis-testing-and-t-tests.html"><a href="practical.-hypothesis-testing-and-t-tests.html#another-exercise-with-non-parametric"><i class="fa fa-check"></i><b>32.5</b> Another exercise with non-parametric</a></li>
</ul></li>
<li class="part"><span><b>VII Review of parts I-V</b></span></li>
<li class="chapter" data-level="" data-path="week-7-overview-reading-week.html"><a href="week-7-overview-reading-week.html"><i class="fa fa-check"></i>Week 7 Overview (Reading week)</a></li>
<li class="part"><span><b>VIII Analysis of Variance (ANOVA)</b></span></li>
<li class="chapter" data-level="" data-path="week-8-overview.html"><a href="week-8-overview.html"><i class="fa fa-check"></i>Week 8 Overview</a></li>
<li class="chapter" data-level="33" data-path="what-is-anova.html"><a href="what-is-anova.html"><i class="fa fa-check"></i><b>33</b> What is ANOVA?</a></li>
<li class="chapter" data-level="34" data-path="one-way-anova.html"><a href="one-way-anova.html"><i class="fa fa-check"></i><b>34</b> One-way ANOVA</a></li>
<li class="chapter" data-level="35" data-path="two-way-anova.html"><a href="two-way-anova.html"><i class="fa fa-check"></i><b>35</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="36" data-path="kruskall-wallis-h-test.html"><a href="kruskall-wallis-h-test.html"><i class="fa fa-check"></i><b>36</b> Kruskall-Wallis H test</a></li>
<li class="chapter" data-level="37" data-path="practical.-anova-and-associated-tests.html"><a href="practical.-anova-and-associated-tests.html"><i class="fa fa-check"></i><b>37</b> <em>Practical</em>. ANOVA and associated tests</a>
<ul>
<li class="chapter" data-level="37.1" data-path="practical.-anova-and-associated-tests.html"><a href="practical.-anova-and-associated-tests.html#anova-exercise-1"><i class="fa fa-check"></i><b>37.1</b> ANOVA Exercise 1</a></li>
<li class="chapter" data-level="37.2" data-path="practical.-anova-and-associated-tests.html"><a href="practical.-anova-and-associated-tests.html#anova-exercise-2"><i class="fa fa-check"></i><b>37.2</b> ANOVA Exercise 2</a></li>
<li class="chapter" data-level="37.3" data-path="practical.-anova-and-associated-tests.html"><a href="practical.-anova-and-associated-tests.html#anova-exercise-3"><i class="fa fa-check"></i><b>37.3</b> ANOVA Exercise 3</a></li>
<li class="chapter" data-level="37.4" data-path="practical.-anova-and-associated-tests.html"><a href="practical.-anova-and-associated-tests.html#anova-exercise-4"><i class="fa fa-check"></i><b>37.4</b> ANOVA Exercise 4</a></li>
</ul></li>
<li class="part"><span><b>IX Counts and Correlation</b></span></li>
<li class="chapter" data-level="" data-path="week-9-overview.html"><a href="week-9-overview.html"><i class="fa fa-check"></i>Week 9 Overview</a></li>
<li class="chapter" data-level="38" data-path="frequency-and-count-data.html"><a href="frequency-and-count-data.html"><i class="fa fa-check"></i><b>38</b> Frequency and count data</a></li>
<li class="chapter" data-level="39" data-path="chi-squared-goodness-of-fit.html"><a href="chi-squared-goodness-of-fit.html"><i class="fa fa-check"></i><b>39</b> Chi-squared goodness of fit</a></li>
<li class="chapter" data-level="40" data-path="chi-squared-test-of-association.html"><a href="chi-squared-test-of-association.html"><i class="fa fa-check"></i><b>40</b> Chi-squared test of association</a></li>
<li class="chapter" data-level="41" data-path="correlation-key-concepts.html"><a href="correlation-key-concepts.html"><i class="fa fa-check"></i><b>41</b> Correlation key concepts</a></li>
<li class="chapter" data-level="42" data-path="correlation-mathematics.html"><a href="correlation-mathematics.html"><i class="fa fa-check"></i><b>42</b> Correlation mathematics</a></li>
<li class="chapter" data-level="43" data-path="correlation-hypothesis-testing.html"><a href="correlation-hypothesis-testing.html"><i class="fa fa-check"></i><b>43</b> Correlation hypothesis testing</a></li>
<li class="chapter" data-level="44" data-path="practical.-analysis-of-count-data-correlation-and-regression.html"><a href="practical.-analysis-of-count-data-correlation-and-regression.html"><i class="fa fa-check"></i><b>44</b> <em>Practical</em>. Analysis of count data, correlation, and regression</a>
<ul>
<li class="chapter" data-level="44.1" data-path="practical.-analysis-of-count-data-correlation-and-regression.html"><a href="practical.-analysis-of-count-data-correlation-and-regression.html#chi-square-exercise-1"><i class="fa fa-check"></i><b>44.1</b> Chi-Square Exercise 1</a></li>
<li class="chapter" data-level="44.2" data-path="practical.-analysis-of-count-data-correlation-and-regression.html"><a href="practical.-analysis-of-count-data-correlation-and-regression.html#chi-square-association-exercise-2"><i class="fa fa-check"></i><b>44.2</b> Chi-Square association Exercise 2</a></li>
<li class="chapter" data-level="44.3" data-path="practical.-analysis-of-count-data-correlation-and-regression.html"><a href="practical.-analysis-of-count-data-correlation-and-regression.html#correlation-exercise-3"><i class="fa fa-check"></i><b>44.3</b> Correlation Exercise 3</a></li>
<li class="chapter" data-level="44.4" data-path="practical.-analysis-of-count-data-correlation-and-regression.html"><a href="practical.-analysis-of-count-data-correlation-and-regression.html#correlation-exercise-4"><i class="fa fa-check"></i><b>44.4</b> Correlation Exercise 4</a></li>
</ul></li>
<li class="part"><span><b>X Linear Regression</b></span></li>
<li class="chapter" data-level="" data-path="week-10-overview.html"><a href="week-10-overview.html"><i class="fa fa-check"></i>Week 10 Overview</a></li>
<li class="chapter" data-level="45" data-path="regression-key-concepts.html"><a href="regression-key-concepts.html"><i class="fa fa-check"></i><b>45</b> Regression key concepts</a></li>
<li class="chapter" data-level="46" data-path="regression-validity.html"><a href="regression-validity.html"><i class="fa fa-check"></i><b>46</b> Regression validity</a></li>
<li class="chapter" data-level="47" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html"><i class="fa fa-check"></i><b>47</b> Introduction to multiple regression</a></li>
<li class="chapter" data-level="48" data-path="model-selection-maybe-remove-this.html"><a href="model-selection-maybe-remove-this.html"><i class="fa fa-check"></i><b>48</b> Model selection (maybe remove this?)</a></li>
<li class="chapter" data-level="49" data-path="practical.-using-regression.html"><a href="practical.-using-regression.html"><i class="fa fa-check"></i><b>49</b> <em>Practical</em>. Using regression</a>
<ul>
<li class="chapter" data-level="49.1" data-path="practical.-using-regression.html"><a href="practical.-using-regression.html#regression-exercise-1"><i class="fa fa-check"></i><b>49.1</b> Regression Exercise 1</a></li>
<li class="chapter" data-level="49.2" data-path="practical.-using-regression.html"><a href="practical.-using-regression.html#regression-exercise-2"><i class="fa fa-check"></i><b>49.2</b> Regression Exercise 2</a></li>
<li class="chapter" data-level="49.3" data-path="practical.-using-regression.html"><a href="practical.-using-regression.html#regression-exercise-3"><i class="fa fa-check"></i><b>49.3</b> Regression Exercise 3</a></li>
<li class="chapter" data-level="49.4" data-path="practical.-using-regression.html"><a href="practical.-using-regression.html#regression-exercise-4"><i class="fa fa-check"></i><b>49.4</b> Regression Exercise 4</a></li>
</ul></li>
<li class="part"><span><b>XI Randomisation approaches</b></span></li>
<li class="chapter" data-level="" data-path="week-11-overview.html"><a href="week-11-overview.html"><i class="fa fa-check"></i>Week 11 Overview</a></li>
<li class="chapter" data-level="50" data-path="introduction-to-randomisation.html"><a href="introduction-to-randomisation.html"><i class="fa fa-check"></i><b>50</b> Introduction to randomisation</a></li>
<li class="chapter" data-level="51" data-path="assumptions-of-randomisation.html"><a href="assumptions-of-randomisation.html"><i class="fa fa-check"></i><b>51</b> Assumptions of randomisation</a></li>
<li class="chapter" data-level="52" data-path="bootstrapping.html"><a href="bootstrapping.html"><i class="fa fa-check"></i><b>52</b> Bootstrapping</a></li>
<li class="chapter" data-level="53" data-path="monte-carlo.html"><a href="monte-carlo.html"><i class="fa fa-check"></i><b>53</b> Monte Carlo</a></li>
<li class="chapter" data-level="54" data-path="practical.-using-r.html"><a href="practical.-using-r.html"><i class="fa fa-check"></i><b>54</b> <em>Practical</em>. Using R</a>
<ul>
<li class="chapter" data-level="54.1" data-path="practical.-using-r.html"><a href="practical.-using-r.html#r-exercise-1"><i class="fa fa-check"></i><b>54.1</b> R Exercise 1</a></li>
<li class="chapter" data-level="54.2" data-path="practical.-using-r.html"><a href="practical.-using-r.html#r-exercise-2"><i class="fa fa-check"></i><b>54.2</b> R Exercise 2</a></li>
<li class="chapter" data-level="54.3" data-path="practical.-using-r.html"><a href="practical.-using-r.html#r-exercise-3"><i class="fa fa-check"></i><b>54.3</b> R Exercise 3</a></li>
</ul></li>
<li class="part"><span><b>XII Statistical Reporting</b></span></li>
<li class="chapter" data-level="" data-path="week-12-overview.html"><a href="week-12-overview.html"><i class="fa fa-check"></i>Week 12 Overview</a></li>
<li class="chapter" data-level="55" data-path="reporting-statistics.html"><a href="reporting-statistics.html"><i class="fa fa-check"></i><b>55</b> Reporting statistics</a></li>
<li class="chapter" data-level="56" data-path="more-introduction-to-r.html"><a href="more-introduction-to-r.html"><i class="fa fa-check"></i><b>56</b> More introduction to R</a></li>
<li class="chapter" data-level="57" data-path="more-getting-started-with-r.html"><a href="more-getting-started-with-r.html"><i class="fa fa-check"></i><b>57</b> More getting started with R</a></li>
<li class="chapter" data-level="58" data-path="practical.-using-r-1.html"><a href="practical.-using-r-1.html"><i class="fa fa-check"></i><b>58</b> <em>Practical</em>. Using R</a>
<ul>
<li class="chapter" data-level="58.1" data-path="practical.-using-r-1.html"><a href="practical.-using-r-1.html#r-exercise-1-1"><i class="fa fa-check"></i><b>58.1</b> R Exercise 1</a></li>
<li class="chapter" data-level="58.2" data-path="practical.-using-r-1.html"><a href="practical.-using-r-1.html#r-exercise-2-1"><i class="fa fa-check"></i><b>58.2</b> R Exercise 2</a></li>
<li class="chapter" data-level="58.3" data-path="practical.-using-r-1.html"><a href="practical.-using-r-1.html#r-exercise-3-1"><i class="fa fa-check"></i><b>58.3</b> R Exercise 3</a></li>
</ul></li>
<li class="part"><span><b>XIII Review of parts (VII-XII)</b></span></li>
<li class="chapter" data-level="" data-path="module-summary.html"><a href="module-summary.html"><i class="fa fa-check"></i>Module summary</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixA_units.html"><a href="appendixA_units.html"><i class="fa fa-check"></i><b>A</b> Statistical units</a></li>
<li class="chapter" data-level="B" data-path="uncertainty_derivation.html"><a href="uncertainty_derivation.html"><i class="fa fa-check"></i><b>B</b> Uncertainty derivation</a></li>
<li class="chapter" data-level="C" data-path="appendixC_tables.html"><a href="appendixC_tables.html"><i class="fa fa-check"></i><b>C</b> Statistical tables</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Techniques for Biological and Environmental Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Chapter_12" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Chapter 12</span> Measures of spread<a href="Chapter_12.html#Chapter_12" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>It is often important to know how much a set of numbers is spread out.
That is, do all of the data cluster close to the mean, or are most values distant from the mean.
For example, all of the numbers below are quite close to the mean of 5.0 (three numbers are exactly 5.0).</p>
<pre><code>4.9, 5.3, 5.0, 4.7, 5.1, 5.0, 5.0</code></pre>
<p>In contrast, all of the numbers that follow are relatively distant to the same mean of 5.0.</p>
<pre><code>3.0, 5.6, 7.8, 1.2, 4.3, 8.2, 4.9</code></pre>
<p>This chapter focuses on summary statistics that describe the spread of data.
The approach in this chapter is similar to <a href="Chapter_11.html#Chapter_11">Chapter 11</a>, which provided verbal and mathematical explanations of measures of central tendency.
We will start with the most intuitive measures of spread, the range and inter-quartile range.
Then, we will move on to some more conceptually challenging measures of spread, the variance, standard deviation, coefficient of variation, and standard error.
These more challenging measures can be a bit confusing at first, but they are absolutely critical for doing statistics.
The best approach to learning them is to see them and practice using them in different contexts, which we will do here, in the <a href="Chapter_13.html#Chapter_13">Chapter 13</a> practical, and throughout the semester.</p>
<div id="the-range" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> The range<a href="Chapter_12.html#the-range" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The range of a set of numbers is probably the most intuitive measure of spread.
It is simply the difference between the highest and the lowest value of a dataset <span class="citation">(<a href="#ref-Sokal1995" role="doc-biblioref">Sokal and Rohlf 1995</a>)</span>.
To calculate it, we just need to take the highest value minus the lowest value.
If we want to be fancy, then we can write a general equation for the range of a variable <span class="math inline">\(X\)</span>,</p>
<p><span class="math display">\[Range(X) = \max(X) - \min(X).\]</span></p>
<p>But really, all that we need to worry about is finding the highest and lowest values, then subtracting.
Consider again the two sets of numbers introduced at the beginning of the chapter.
In examples, it is often helpful to imagine numbers as something concrete that has been measured, so suppose that these numbers are the measured masses (in grams) of leaves from two different plants.
Below are the masses of plant A, in which leaf masses are very similar and close to the mean of 5.</p>
<pre><code>4.9, 5.3, 5.0, 4.7, 5.1, 5.0, 5.0</code></pre>
<p>Plant B masses are below, which are more spread out around the same mean of 5.</p>
<pre><code>3.0, 5.6, 7.8, 1.2, 4.3, 8.2, 4.9</code></pre>
<p>To get the range of plant A, we just need to find the highest (5.3 g) and lowest (4.7 g) mass, then subtract,</p>
<p><span class="math display">\[Range(Plant\:A) = 5.3 - 4.7 = 0.6\]</span></p>
<p>Plant A therefore has a range of 0.6 g.
We can do the same for plant B, which has a highest value of 8.2 g and lowest value of 1.2 g,</p>
<p><span class="math display">\[Range(Plant\:B) = 8.2 - 1.2 = 7.0\]</span></p>
<p>Plant B therefore has a much higher range than plant A.</p>
<p>It is important to mention that the range is highly sensitive to outliers <span class="citation">(<a href="#ref-Navarro2022" role="doc-biblioref">Navarro and Foxcroft 2022</a>)</span>.
Just adding a single number to either plant A or plant B could dramatically change the range.
For example, imagine if we measured a leaf in plant A to have a mass of 19.7 g (i.e., we found a huge leaf!).
The range of plant A would then be <span class="math inline">\(19.7 - 4.7 = 14\)</span>.
Just this one massive leaf would then make the range of plant A double the range of plant B.
This lack of robustness can really limit how useful the range is as a statistical measure of spread.</p>
</div>
<div id="the-inter-quartile-range" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> The inter-quartile range<a href="Chapter_12.html#the-inter-quartile-range" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The inter-quartile range (usually abbreviated as ‘IQR’) is conceptually the same as the range.
The only difference is that we are calculating the range between quartiles rather than the range between the highest and lowest numbers in the dataset.
A general formula subtracting the first quartile (<span class="math inline">\(Q_{1}\)</span>) from the third quartile (<span class="math inline">\(Q_{3}\)</span>) is,</p>
<p><span class="math display">\[IQR = Q_{3} - Q_{1}.\]</span></p>
<p>Recall from <a href="Chapter_11.html#Chapter_11">Chapter 11</a> how to calculate first and third quartiles.
As a reminder, we can sort the leaf masses for plant A below.</p>
<pre><code>4.7, 4.9, 5.0, 5.0, 5.0, 5.1, 5.3</code></pre>
<p>The first quartile will be the mean between 4.9 and 5.0 (4.95).
The second quartile will be the the mean between 5.0 and 5.1 (5.05).
The IQR of plant A is therefore,</p>
<p><span class="math display">\[IQR_{plant\:A} = 5.05 - 4.95 = 0.1.\]</span></p>
<p>We can calculate the IQR for plant B in the same way.
Here are the masses of plant B leaves sorted.</p>
<pre><code>1.2, 3.0, 4.3, 4.9, 5.6, 7.8, 8.2</code></pre>
<p>The first quartile of plant B is 3.65, and the third quartile is 6.70.
To get the IQR of plant B,</p>
<p><span class="math display">\[IQR_{plant\:B} = 6.70 - 3.65 = 3.05.\]</span></p>
<p>An important point about the IQR is that it is more robust than the range <span class="citation">(<a href="#ref-Dytham2011" role="doc-biblioref">Dytham 2011</a>)</span>.
Recall that if we found an outlier leaf of 19.7 g on plant A, it would change the range of plant leaf mass from 0.6 g to 14 g.
The IQR is not nearly so sensitive.
If we include the outlier, the first quartile for plant A changes from <span class="math inline">\(Q_{1} = 4.95\)</span> to <span class="math inline">\(Q_{1} = 4.975\)</span>.
The second quartile changes from <span class="math inline">\(Q_{3} = 5.05\)</span> to <span class="math inline">\(Q_{3} = 5.150\)</span>.
The resulting IQR is therefore <span class="math inline">\(5.150 - 4.975 = 0.175\)</span>.
Hence, the IQR only changes from 0.1 to 0.175, rather than from 0.6 to 14.
The one outlier therefore has a huge effect on the range, but only a modest effect on the IQR.</p>
</div>
<div id="the-variance" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> The variance<a href="Chapter_12.html#the-variance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The range and inter-quartile range were reasonably intuitive, in the sense that it is not too difficult to think about what a range of 10, e.g., actually means in terms of the data.
We now move into measures of spread that are less intuitive.
These measures of spread are the variance, standard deviation, coefficient of variation, and standard error.
These can be confusing and unintuitive at first, but they are extremely useful.
The variance of a dataset (is a measure of the expected distance of data from the mean.
To calculate the variance of a sample, we need to know the sample size (<span class="math inline">\(N\)</span>, i.e., how many measurements in total), and the mean of the sample (<span class="math inline">\(\bar{x}\)</span>).
We can calculate the variance of a sample (<span class="math inline">\(s^{2}\)</span>) as follows,</p>
<p><span class="math display">\[s^{2} = \frac{1}{N - 1}\sum_{i = 1}^{N}\left(x_{i} - \bar{x} \right)^{2}.\]</span></p>
<p>This looks like a lot, but we can break down what the equation is doing verbally.
First, we can look inside the summation (<span class="math inline">\(\sum\)</span>).
Here we are taking an individual measurement <span class="math inline">\(x_{i}\)</span>, subtracting the mean <span class="math inline">\(\bar{x}\)</span>, then squaring.
We do this for each <span class="math inline">\(x_{i}\)</span>, summing up all of the values from <span class="math inline">\(i = 1\)</span> to <span class="math inline">\(i = N\)</span>.
This part of the equation is called the <strong>sum of squares</strong> (<span class="math inline">\(SS\)</span>),</p>
<p><span class="math display">\[SS = \sum_{i = 1}^{N}\left(x_{i} - \bar{x} \right)^{2}\]</span></p>
<p>That is, we need to subtract the mean of each value <span class="math inline">\(x_{i}\)</span>, square the result, and add everything up.
Once we have this sum <span class="math inline">\(SS\)</span>, then we just need to multiply by <span class="math inline">\(1 / (N - 1)\)</span> to get the variance.</p>
<p>An example of how to do the actual calculation should help make it easier to understand what is going on.
We can use the same values from plant A earlier.</p>
<pre><code>4.9, 5.3, 5.0, 4.7, 5.1, 5.0, 5.0</code></pre>
<p>To calculate the variance of plant A leaf masses, we start with the sum of squares.
That is, take 4.7, subtract the sample mean of 5.0 (<span class="math inline">\(4.7 - 5.0 = -0.3\)</span>), then square the result (<span class="math inline">\((-0.3)^{2} = 0.09\)</span>).
We do the same for 4.9, <span class="math inline">\((4.9 - 5.0)^{2} = 0.1\)</span>, and add it to the 0.09, then continue down the list of numbers finishing with 5.3.
This is what the sum of squares calculation looks like all written out,</p>
<p><span class="math display">\[SS = (4.9 - 5)^{2} + (5.3 - 5)^{2} + (5 - 5)^{2} + (4.7 - 5)^{2} + (5.1 - 5)^{2} + (5 - 5)^{2} + (5 - 5)^{2}.\]</span></p>
<p>Remember that the calculations in parentheses need to be done first, so the next step for calculating the sum of squares would be the following,</p>
<p><span class="math display">\[SS = (-0.1)^{2} + (0.3)^{2} + (0)^{2} + (-0.3)^{2} + (0.1)^{2} + (0)^{2} + (0)^{2}.\]</span></p>
<p>Next, we need to square all of the values,</p>
<p><span class="math display">\[SS = 0.01 + 0.09 + 0 + 0.09 + 0.01 + 0 + 0.\]</span></p>
<p>If we sum the above, we get <span class="math inline">\(SS = 0.2\)</span>.
We now just need to multiply this by <span class="math inline">\(1 / N( - 1)\)</span>, where <span class="math inline">\(N = 7\)</span> because this is the total number of measurements in the plant A dataset,</p>
<p><span class="math display">\[s^{2} = \frac{1}{7 - 1}\left(0.2\right).\]</span></p>
<p>From the above, we get a variance of approximately <span class="math inline">\(s^{2} = 0.0333\)</span>.</p>
<p>Fortunately, it will almost never be necessary to calculate a variance manually in this way.
Any statistical software will do all of these steps and calculate the variance for us (the <a href="Chapter_13.html#Chapter_13">Chapter 13</a> explains how in Jamovi).
The only reason that we present the step-by-step calculation here is to help explain the equation for <span class="math inline">\(s^{2}\)</span>.
The details can be helpful for understanding how the variance works as a measure of spread.
For example, note that what we are really doing here is getting the distance of each value from the mean, <span class="math inline">\(x_{i} - \bar{x}\)</span>.
If these distances tend to be large, then it means that most data points (<span class="math inline">\(x_{i}\)</span>) are far away from the mean (<span class="math inline">\(\bar{x}\)</span>), and the variance (<span class="math inline">\(s^{2}\)</span>) will therefore increase.
The differences <span class="math inline">\(x_{i} - \bar{x}\)</span> are squared because we need all of the values to be positive, so that variance increases regardless of whether a value <span class="math inline">\(x_{i}\)</span> is higher or lower than the mean.
It does not matter if <span class="math inline">\(x_{i}\)</span> is 0.1 lower than <span class="math inline">\(\bar{x}\)</span> (i.e., <span class="math inline">\(x_{i} - \bar{x} = -0.1\)</span>), or 0.1 higher (i.e., <span class="math inline">\(x_{i} - \bar{x} = 0.1\)</span>).
In both cases, the deviation from the mean is the same.
Moreover, if we did not square the values, then the sum of <span class="math inline">\(x_{i} - \bar{x}\)</span> values would always be 0 (you can try this yourself)<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>.
Lastly, it turns out that the variance is actually a special case of a more general concept called the <em>covariance</em>, which we will look at later in <a href="#Chapter_41">Chapter 41</a> and makes the squaring of differences make a bit more sense.</p>
<p>We sum up all of the squared deviations to get <span class="math inline">\(SS\)</span>, then divide by the sample size minus 1, to get the mean squared deviation from the mean.
That is, the whole process gives us the average squared deviation from the mean.
But wait, why is it the sample size minus 1, <span class="math inline">\(N - 1\)</span>?
Why would we subtract 1 here?
The short answer is that in calculating a <em>sample</em> variance, <span class="math inline">\(s^{2}\)</span>, we are almost always trying to estimate the corresponding <em>population</em> variance (<span class="math inline">\(\sigma^{2}\)</span>).
And if we were to just use <span class="math inline">\(N\)</span> instead of <span class="math inline">\(N - 1\)</span>, then our <span class="math inline">\(s^{2}\)</span> would be a biased estimate of <span class="math inline">\(\sigma^{2}\)</span> (see <a href="Chapter_4.html#Chapter_4">Chapter 4</a> for a reminder on the difference between samples and populations).
By subtracting 1, we are correcting for this bias to get a more accurate estimate of the population variance.
It is not necessary to do this ourselves; statistical software like Jamovi and R will do it automatically.
This is really all that it is necessary to know for now, but see this footnote<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> for a bit more detailed explanation to try to make this intuitive (it is actually quite cool!).
Later, we will explore the broader concept of <em>degrees of freedom</em>, which explains why we need to take into account the number of parameters in a statistic that are free to vary when calculating a statistic<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>.</p>
<p>This was a lot of information.
The variance is not an intuitive concept.
In addition to being a challenge to calculate, the calculation of a variance leaves us with a value in units squared.
That is, for the example of plant leaf mass in grams, the variance is measured in grams squared, <span class="math inline">\(g^{2}\)</span>, which is not particularly easy to interpret.
For more on this, <span class="citation">Navarro and Foxcroft (<a href="#ref-Navarro2022" role="doc-biblioref">2022</a>)</span> have a really good <a href="https://davidfoxcroft.github.io/lsj-book/04-Descriptive-statistics.html#variance">section</a> on the variance.
Despite its challenges as a descriptive statistic, the variance has some mathematical properties that are very useful <span class="citation">(<a href="#ref-Navarro2022" role="doc-biblioref">Navarro and Foxcroft 2022</a>)</span>, especially in the biological and environmental sciences.
For example, variances are additive, meaning that if we are measuring two separate characteristics of a sample, A and B, then the variance of A+B equals the variance of A plus the variance of B; i.e., <span class="math inline">\(Var(A + B) = Var(A) + Var(B)\)</span> <a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>.
This is relevant to Evolution and Genetics when measuring heritability in quantitative genetics.
Here, the total variance in the phenotype of a population (e.g., body mass of animals) can be partitioned into variance attributable to genetics plus variance attributable to the environment,</p>
<p><span class="math display">\[Var(Phenotype) = Var(Genotype) + Var(Environment).\]</span>
This is also sometimes written as <span class="math inline">\(V_{P} = V_{G} + V_{E}\)</span>.
Applying this equation to calculate heritability (<span class="math inline">\(H^{2} = V_{G} / V_{P}\)</span>) can be used to predict how a population will respond to natural selection.
This is just one place where variance reveals itself to be a highly useful statistic in practice.
As a descriptive statistic to communicate the spread of a variable, it usually makes more sense to calculate the standard deviation of the mean.</p>
</div>
<div id="the-standard-deviation" class="section level2 hasAnchor" number="12.4">
<h2><span class="header-section-number">12.4</span> The standard deviation<a href="Chapter_12.html#the-standard-deviation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The standard deviation of the mean (<span class="math inline">\(s\)</span>) is just the square root of the variance,</p>
<p><span class="math display">\[s = \sqrt{\frac{1}{N - 1}\sum_{i = 1}^{N}\left(x_{i} - \bar{x} \right)^{2}}.\]</span></p>
<p>This is a simple step, mathematically, but it also is easier to understand conceptually as a measure of spread <span class="citation">(<a href="#ref-Navarro2022" role="doc-biblioref">Navarro and Foxcroft 2022</a>)</span>.
By taking the square root of the variance, our units are no longer squared, so we can interpret the standard deviation in the same terms as our original data.
For example, the leaf masses of plant A and plant B in the example above were measured in grams.
While the variance of these masses were in <span class="math inline">\(g^{2}\)</span>, the standard deviation is in <span class="math inline">\(g\)</span>, just like the original measurements.
For plant A, we calculated a leaf mass variance of <span class="math inline">\(s^{2} = 0.0333\:g^{2}\)</span>, which means that the standard deviation of leaf masses is <span class="math inline">\(s = \sqrt{0.0333}\:g^{2} = 0.1825\:g\)</span>.
Because we are reporting <span class="math inline">\(s\)</span> in the original units, it is a very useful measure of spread to report, and it is an important one to be able to interpret.
To help with the interpretation, here is <a href="https://bradduthie.shinyapps.io/forest/">an interactive tool</a> showing how the heights of trees in a forest change across different standard deviation values<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>.
Here is another <a href="https://bradduthie.shinyapps.io/normal_pos_neg/">interactive tool</a> showing how the shape of a histogram changes when the standard deviation of a distribution is changed<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>.
The practical in <a href="Chapter_13.html#Chapter_13">Chapter 13</a> explains how to calculate the standard deviation in Jamovi.</p>
</div>
<div id="the-coefficient-of-variation" class="section level2 hasAnchor" number="12.5">
<h2><span class="header-section-number">12.5</span> The coefficient of variation<a href="Chapter_12.html#the-coefficient-of-variation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The coefficient of variation (CV) is just the standard deviation divided by the mean,</p>
<p><span class="math display">\[CV = \frac{s}{\bar{x}}.\]</span></p>
<p>Dividing by the mean seems a bit arbitrary at first, but this can often be useful for comparing variables with different means or different units.
The reason for this is that the units cancel out when dividing the standard deviation by the mean.
For example, for the leaf masses of plant A, we calculated a standard deviation of 0.1825 g and a mean of 5 g.
We can see the units cancel below,</p>
<p><span class="math display">\[CV = \frac{0.1825\:g}{5\:g} = 0.0365.\]</span></p>
<p>The resulting CV of 0.0365 has no units; it is <em>dimensionless</em> <span class="citation">(<a href="#ref-Lande1977" role="doc-biblioref">Lande 1977</a>)</span>.
Because it has no units, it often used to compare measurements with much different means or with different measurement units.
For example, <span class="citation">Sokal and Rohlf (<a href="#ref-Sokal1995" role="doc-biblioref">1995</a>)</span> suggest that biologists might want to compare tail length variation between animals with much different body sizes, such as elephants and mice.
The standard deviation of tail lengths between these two species will likely be much different just because of their difference in size, so by standardising by mean tail length, it can be easier to compare relative standard deviation.
This is a common application of the CV in biology, but it needs to be interpreted carefully <span class="citation">(<a href="#ref-Pelabon2020" role="doc-biblioref">Pélabon et al. 2020</a>)</span>.</p>
<p>Often, we will want to express the coefficient of variation as a percentage of the mean.
To do this, we just need to multiply the CV above by 100%.
For example, to express the CV as a percentage, we would multiply the 0.0365 above by 100%, which would give us a final answer of <span class="math inline">\(CV = 3.65\)</span>%.</p>
</div>
<div id="the-standard-error" class="section level2 hasAnchor" number="12.6">
<h2><span class="header-section-number">12.6</span> The standard error<a href="Chapter_12.html#the-standard-error" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The standard error of the mean is the last measurement that we will introduce here.
It is slightly different than the previous estimates in that it is a measure of the variation in the <em>mean</em> of a sample rather than the sample itself.
That is, the standard error tells us how far our sample mean <span class="math inline">\(\bar{x}\)</span> is expected to deviate from the true mean <span class="math inline">\(\mu\)</span>.
Technically, the standard error of the mean is the standard deviation <em>of sample means</em> rather than the standard deviation <em>of samples</em>.
What does that even mean?
It is easier to explain with a concrete example.</p>
<p>Imagine that we want to measure nitrogen levels in the water of Airthrey Loch (the loch at the centre of campus at the University of Stirling)
We collect 12 water samples and record the nitrate levels in milligrams per litre (mg/l).
The measurements are reported below.</p>
<pre><code>0.63, 0.60, 0.53, 0.72, 0.61, 0.48, 0.67, 0.59, 0.67, 0.54, 0.47, 0.87</code></pre>
<p>We can calculate the mean of the above sample to be <span class="math inline">\(\bar{x} = 0.615\)</span>, and we can calculate the standard deviation of the sample to be <span class="math inline">\(s = 0.111\)</span>.
We do not know what the <em>true</em> mean <span class="math inline">\(\mu\)</span> is, but our best guess is the sample mean <span class="math inline">\(\bar{x}\)</span>.
Suppose, however, that we then went back to the loch to collect another 8 measurements (assume that the nitrogen level of the lake has not changed in the meantime).
We would expect to get similar values as our first 8 measurements, but certainly not the <em>exact</em> same measurements, right?
The sample mean of these new measurements would also be a bit different.
Maybe we actually go out and do this and get the following new sample.</p>
<pre><code>0.47, 0.56, 0.72, 0.61, 0.54, 0.64, 0.68, 0.54, 0.48, 0.59, 0.62, 0.78</code></pre>
<p>The mean of our new sample is 0.603, which is a bit different from our first.
In other words, the sample means vary.
We can therefore ask what the variance and standard deviation is <em>of the sample means</em>.
In other words, suppose that we kept going back out to the loch, collecting 8 new samples, and recording the sample mean each time?
The standard deviation of those sample means would be the standard error.
It is the standard deviation of <span class="math inline">\(\bar{x}\)</span> values around the true mean <span class="math inline">\(\mu\)</span>.
But we do not actually need to go through the repetitive resampling process to estimate the standard error.
We can estimate it with just the standard deviation and the sample size.
To do this, we just need to take the standard deviation of the sample (<span class="math inline">\(s\)</span>) and divide by the square root of the sample size (<span class="math inline">\(\sqrt{N}\)</span>),</p>
<p><span class="math display">\[SE = \frac{s}{\sqrt{N}}.\]</span></p>
<p>In the case of the first 12 samples from the loch in the example above,</p>
<p><span class="math display">\[SE = \frac{0.111}{\sqrt{12}} = 0.032.\]</span></p>
<p>The standard error is important because it can be used to evaluate the uncertainty of the sample mean in comparison with the true mean.
We can use the standard error to place confidence intervals around our sample mean to express this uncertainty.
We will calculate confidence intervals in <a href="#Chapter_19">Chapter 19</a>, so it is important to understand what the standard error is measuring.</p>
<p>If the concept of standard error is still a but unclear, we can work through one more hypothetical example.
Suppose again that we want to measure the nitrogen concentration of a loch.
This time, however, assume that we somehow <em>know</em> that the true mean N concentration is <span class="math inline">\(\mu = 0.7\)</span>, and that the standard deviation of water sample N concentration is <span class="math inline">\(\sigma = 0.1\)</span>.
Of course, we can never actually know the <em>true</em> parameter values, but we can use a computer to simulate sampling from a population in which the true parameter values are known.
In Table 12.1, we simulate the process of going out and collecting 10 water samples from Airthrey Loch.
This collecting of 10 water samples is repeated 20 different times.
Each row is a different sampling effort, and columns report the 10 samples from each effort.</p>
<table>
<caption><span id="tab:unnamed-chunk-40">Table 12.1: </span>Simulated samples of nitrogen content from water samples of Airthrey Loch. Values are sampled from a normal distribution with a mean of 0.7 and a standard deviation 0.1.</caption>
<tbody>
<tr class="odd">
<td align="left">Sample_1</td>
<td align="right">0.80</td>
<td align="right">0.67</td>
<td align="right">0.77</td>
<td align="right">0.64</td>
<td align="right">0.71</td>
<td align="right">0.69</td>
<td align="right">0.80</td>
<td align="right">0.61</td>
<td align="right">0.79</td>
<td align="right">0.64</td>
</tr>
<tr class="even">
<td align="left">Sample_2</td>
<td align="right">0.81</td>
<td align="right">0.57</td>
<td align="right">0.66</td>
<td align="right">0.63</td>
<td align="right">0.67</td>
<td align="right">0.75</td>
<td align="right">0.82</td>
<td align="right">0.65</td>
<td align="right">0.75</td>
<td align="right">0.67</td>
</tr>
<tr class="odd">
<td align="left">Sample_3</td>
<td align="right">0.63</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">0.74</td>
<td align="right">0.67</td>
<td align="right">0.77</td>
<td align="right">0.70</td>
<td align="right">0.56</td>
<td align="right">0.63</td>
<td align="right">0.71</td>
</tr>
<tr class="even">
<td align="left">Sample_4</td>
<td align="right">0.69</td>
<td align="right">0.88</td>
<td align="right">0.74</td>
<td align="right">0.71</td>
<td align="right">0.73</td>
<td align="right">0.82</td>
<td align="right">0.70</td>
<td align="right">0.65</td>
<td align="right">0.63</td>
<td align="right">0.69</td>
</tr>
<tr class="odd">
<td align="left">Sample_5</td>
<td align="right">0.64</td>
<td align="right">0.58</td>
<td align="right">0.69</td>
<td align="right">0.65</td>
<td align="right">0.68</td>
<td align="right">0.86</td>
<td align="right">0.97</td>
<td align="right">0.64</td>
<td align="right">0.59</td>
<td align="right">0.62</td>
</tr>
<tr class="even">
<td align="left">Sample_6</td>
<td align="right">0.60</td>
<td align="right">0.57</td>
<td align="right">0.76</td>
<td align="right">0.74</td>
<td align="right">0.76</td>
<td align="right">0.83</td>
<td align="right">0.60</td>
<td align="right">0.77</td>
<td align="right">0.85</td>
<td align="right">0.81</td>
</tr>
<tr class="odd">
<td align="left">Sample_7</td>
<td align="right">0.77</td>
<td align="right">0.69</td>
<td align="right">0.65</td>
<td align="right">0.77</td>
<td align="right">0.93</td>
<td align="right">0.65</td>
<td align="right">0.47</td>
<td align="right">0.60</td>
<td align="right">0.55</td>
<td align="right">0.58</td>
</tr>
<tr class="even">
<td align="left">Sample_8</td>
<td align="right">0.70</td>
<td align="right">0.71</td>
<td align="right">0.75</td>
<td align="right">0.78</td>
<td align="right">0.83</td>
<td align="right">0.77</td>
<td align="right">0.62</td>
<td align="right">0.72</td>
<td align="right">0.72</td>
<td align="right">0.61</td>
</tr>
<tr class="odd">
<td align="left">Sample_9</td>
<td align="right">0.51</td>
<td align="right">0.85</td>
<td align="right">0.65</td>
<td align="right">0.88</td>
<td align="right">0.72</td>
<td align="right">0.57</td>
<td align="right">0.62</td>
<td align="right">0.76</td>
<td align="right">0.88</td>
<td align="right">0.91</td>
</tr>
<tr class="even">
<td align="left">Sample_10</td>
<td align="right">0.76</td>
<td align="right">0.86</td>
<td align="right">0.56</td>
<td align="right">0.76</td>
<td align="right">0.79</td>
<td align="right">0.65</td>
<td align="right">0.73</td>
<td align="right">0.75</td>
<td align="right">0.68</td>
<td align="right">0.60</td>
</tr>
<tr class="odd">
<td align="left">Sample_11</td>
<td align="right">0.53</td>
<td align="right">0.83</td>
<td align="right">0.70</td>
<td align="right">0.67</td>
<td align="right">0.57</td>
<td align="right">0.83</td>
<td align="right">0.85</td>
<td align="right">0.72</td>
<td align="right">0.69</td>
<td align="right">0.57</td>
</tr>
<tr class="even">
<td align="left">Sample_12</td>
<td align="right">0.55</td>
<td align="right">0.67</td>
<td align="right">0.66</td>
<td align="right">0.66</td>
<td align="right">0.56</td>
<td align="right">0.73</td>
<td align="right">0.93</td>
<td align="right">0.74</td>
<td align="right">0.64</td>
<td align="right">0.67</td>
</tr>
<tr class="odd">
<td align="left">Sample_13</td>
<td align="right">0.62</td>
<td align="right">0.72</td>
<td align="right">0.54</td>
<td align="right">0.70</td>
<td align="right">0.53</td>
<td align="right">0.64</td>
<td align="right">0.54</td>
<td align="right">0.93</td>
<td align="right">0.79</td>
<td align="right">0.69</td>
</tr>
<tr class="even">
<td align="left">Sample_14</td>
<td align="right">0.81</td>
<td align="right">0.66</td>
<td align="right">0.83</td>
<td align="right">0.59</td>
<td align="right">0.94</td>
<td align="right">0.49</td>
<td align="right">0.71</td>
<td align="right">0.88</td>
<td align="right">0.60</td>
<td align="right">0.79</td>
</tr>
<tr class="odd">
<td align="left">Sample_15</td>
<td align="right">0.72</td>
<td align="right">0.70</td>
<td align="right">0.69</td>
<td align="right">0.75</td>
<td align="right">0.71</td>
<td align="right">0.66</td>
<td align="right">0.76</td>
<td align="right">0.61</td>
<td align="right">0.79</td>
<td align="right">0.73</td>
</tr>
<tr class="even">
<td align="left">Sample_16</td>
<td align="right">0.61</td>
<td align="right">0.67</td>
<td align="right">0.70</td>
<td align="right">0.59</td>
<td align="right">0.81</td>
<td align="right">0.76</td>
<td align="right">0.59</td>
<td align="right">0.70</td>
<td align="right">0.66</td>
<td align="right">0.65</td>
</tr>
<tr class="odd">
<td align="left">Sample_17</td>
<td align="right">0.71</td>
<td align="right">0.65</td>
<td align="right">0.66</td>
<td align="right">0.66</td>
<td align="right">0.76</td>
<td align="right">0.54</td>
<td align="right">0.55</td>
<td align="right">0.70</td>
<td align="right">0.74</td>
<td align="right">0.79</td>
</tr>
<tr class="even">
<td align="left">Sample_18</td>
<td align="right">0.72</td>
<td align="right">0.61</td>
<td align="right">0.62</td>
<td align="right">0.81</td>
<td align="right">0.76</td>
<td align="right">0.68</td>
<td align="right">0.79</td>
<td align="right">0.59</td>
<td align="right">0.73</td>
<td align="right">0.63</td>
</tr>
<tr class="odd">
<td align="left">Sample_19</td>
<td align="right">0.76</td>
<td align="right">0.60</td>
<td align="right">0.74</td>
<td align="right">0.79</td>
<td align="right">0.74</td>
<td align="right">0.67</td>
<td align="right">0.77</td>
<td align="right">0.88</td>
<td align="right">0.68</td>
<td align="right">0.72</td>
</tr>
<tr class="even">
<td align="left">Sample_20</td>
<td align="right">0.64</td>
<td align="right">0.69</td>
<td align="right">0.64</td>
<td align="right">0.70</td>
<td align="right">0.47</td>
<td align="right">0.63</td>
<td align="right">0.76</td>
<td align="right">0.70</td>
<td align="right">0.60</td>
<td align="right">0.80</td>
</tr>
</tbody>
</table>
<p>We can calculate the mean of each sample by calculating the mean of each row.
These means are reported below.</p>
<pre><code>##       [,1]  [,2] [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
## [1,] 0.712 0.698 0.69 0.724 0.692 0.729 0.666 0.721 0.735 0.714
## [2,] 0.696 0.681 0.67 0.730 0.712 0.674 0.676 0.694 0.735 0.663</code></pre>
<p>The standard deviation of the sample means reported above is 0.0239987.
Now suppose that we only had Sample 1 (i.e., the top row of data).
The standard deviation of Sample 1 is <span class="math inline">\(s =\)</span> 0.0729992.
We can calculate the standard error from these sample values below,</p>
<p><span class="math display">\[s = \frac{0.0729992}{\sqrt{10}} = 0.0230844.\]</span></p>
<p>The estimate of the standard error from calculating the standard deviation of the sample means is therefore 0.0239987, and the estimate from just using the standard error formula and data from only Sample 1 is 0.0230844.
These are reasonably close, and would be even closer if we had either a larger sample size in each sample (i.e., higher <span class="math inline">\(N\)</span>) or a larger number of samples.</p>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Dytham2011" class="csl-entry">
Dytham, Calvin. 2011. <em><span class="nocase">Choosing and Using Statistics: A Biologist’s Guide</span></em>. John Wiley &amp; Sons.
</div>
<div id="ref-Lande1977" class="csl-entry">
Lande, Russell. 1977. <span>“<span class="nocase">On comparing coefficients of variation.</span>”</span> <em>Systematic Zoology</em> 26 (2): 214–17.
</div>
<div id="ref-Navarro2022" class="csl-entry">
Navarro, Danielle J, and David R Foxcroft. 2022. <em><span class="nocase">Learning Statistics with Jamovi</span></em>. (Version 0.75). <a href="https://doi.org/10.24384/hgc3-7p15">https://doi.org/10.24384/hgc3-7p15</a>.
</div>
<div id="ref-Pelabon2020" class="csl-entry">
Pélabon, Christophe, Christoffer H Hilde, Sigurd Einum, and Marlène Gamelon. 2020. <span>“<span class="nocase">On the use of the coefficient of variation to quantify and compare trait variation</span>.”</span> <em>Evolution Letters</em> 4 (3): 180–88. <a href="https://doi.org/10.1002/evl3.171">https://doi.org/10.1002/evl3.171</a>.
</div>
<div id="ref-Sokal1995" class="csl-entry">
Sokal, Robert R, and F James Rohlf. 1995. <em><span>Biometry</span></em>. 3rd ed. New York: W. H. Freeman; Company.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>If you are wondering why we square the difference <span class="math inline">\(x_{i} - \bar{x}\)</span> instead of just taking its absolute value, this is an excellent question! You have just invented something called the mean absolute deviation. There are some reasons why the mean absolute deviation is not as good of a measure of spread as the variance. <span class="citation">Navarro and Foxcroft (<a href="#ref-Navarro2022" role="doc-biblioref">2022</a>)</span> explain the mean absolute deviation, and how it relates to the variance, very well in section 4.2.3 of their textbook. We will not get into these points here, but it would be good to check out <span class="citation">Navarro and Foxcroft (<a href="#ref-Navarro2022" role="doc-biblioref">2022</a>)</span> for more explanation.<a href="Chapter_12.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>To get the true population variance <span class="math inline">\(\sigma^{2}\)</span>, we would also need to know the true mean <span class="math inline">\(\mu\)</span>. But we can only estimate <span class="math inline">\(\mu\)</span> from the sample, <span class="math inline">\(\bar{x}\)</span>. That is, what we would really want to calculate is <span class="math inline">\(x_{i} - \mu\)</span>, but the best we can do is <span class="math inline">\(x_{i} - \bar{x}\)</span>. The consequence of this is that there will be some error that underestimates the true distance of <span class="math inline">\(x_{i}\)</span> values from the population mean, <span class="math inline">\(\mu\)</span>. Here is the really cool part; to determine the extent to which our estimate of the variance is biased by using <span class="math inline">\(\bar{x}\)</span> instead of <span class="math inline">\(\mu\)</span>, we just need to know the expected squared difference between the two values, <span class="math inline">\((\bar{x} - \mu)^{2}\)</span>. It turns out that this difference (i.e., the bias of our estimate <span class="math inline">\(s^{2}\)</span>) is just <span class="math inline">\(\sigma^{2} / N\)</span>; that is, the true variance of the population divided by the sample size. If we subtract this value from <span class="math inline">\(\sigma^{2}\)</span>, so <span class="math inline">\(\sigma^{2} - \sigma^{2}/N\)</span>, then we can get the expected difference between the true variance and the estimate from the sample size. We can rearrange <span class="math inline">\(\sigma^{2} - \sigma^{2}/N\)</span> to get <span class="math inline">\(\sigma^{2} \times (N - 1)/N\)</span>, which means that we need to correct our sample variance by <span class="math inline">\(N / (N-1)\)</span> to get an unbiased estimate of <span class="math inline">\(\sigma^{2}\)</span>. If all of this is confusing, that is okay! This is really only relevant for those interested in statistical theory, which is not the focus of this module.<a href="Chapter_12.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Briefly, in the case of sample variance, note that we needed to use all the values <span class="math inline">\(x_{i}\)</span> in the dataset and the sample mean <span class="math inline">\(\bar{x}\)</span>. But if we know what all of the <span class="math inline">\(x_{i}\)</span> values are, then we also know <span class="math inline">\(\bar{x}\)</span>. And if we know all but one value of <span class="math inline">\(x_{i}\)</span> and <span class="math inline">\(\bar{x}\)</span>, then we could figure out the last <span class="math inline">\(x_{i}\)</span>. Hence, while we are using <span class="math inline">\(N\)</span> values in the calculation of <span class="math inline">\(s^{2}\)</span>, the use of <span class="math inline">\(\bar{x}\)</span> reduces the degree to which these values are free to vary. We have lost 1 degree of freedom in the calculation of <span class="math inline">\(\bar{x}\)</span>, so we need to account for this in our calculation of <span class="math inline">\(s^{2}\)</span> by dividing by <span class="math inline">\(N - 1\)</span>. This is another way to think about the <span class="math inline">\(N - 1\)</span> correction factor <span class="citation">(<a href="#ref-Sokal1995" role="doc-biblioref">Sokal and Rohlf 1995</a>)</span> explained in the previous footnote.<a href="Chapter_12.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>This has one caveat, which is not important for now. Values of A and B must be uncorrelated. That is, A and B cannot covary. If A and B covary, i.e., <span class="math inline">\(Cov(A, B) \neq 0\)</span>, then <span class="math inline">\(Var(A+B) = Var(A) + Var(B) + Cov(A, B)\)</span>. That is, we need to account for the covariance when calculating <span class="math inline">\(Var(A+B)\)</span>.<a href="Chapter_12.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>Here is the full URL: <a href="https://bradduthie.shinyapps.io/forest/" class="uri">https://bradduthie.shinyapps.io/forest/</a><a href="Chapter_12.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Here is the full URL: <a href="https://bradduthie.shinyapps.io/normal_pos_neg/" class="uri">https://bradduthie.shinyapps.io/normal_pos_neg/</a><a href="Chapter_12.html#fnref10" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chapter_11.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Chapter_13.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-Summary_statistics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
