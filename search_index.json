[["index.html", "Statistical Techniques for Biological and Environmental Sciences Preface 0.1 What is statistics? 0.2 Why this module is important 0.3 Teaching overview 0.4 Assessment overview 0.5 Jamovi statistical software 0.6 Textbooks 0.7 Canvas 0.8 Timetable", " Statistical Techniques for Biological and Environmental Sciences Brad Duthie 2022-11-06 Preface Welcome to the module. This workbook will be used throughout the semester and contain all of the information that you need for the statistical techniques (SCIU4T4) module. 0.1 What is statistics? An explanation of the material, and what will be taught. 0.2 Why this module is important Some discussion of module importance 0.3 Teaching overview Here is how you will be taught, with online lectures, reading assignments, and face-to-face practicals. 0.4 Assessment overview You will have one formative test and two summatitive tests. You will also have one mock exam and one exam exam. 0.4.1 Test 1F Information about Test 1F 0.4.2 Test 1S Information about Test 1S 0.4.3 Test 2S Information about Test 1S 0.4.4 Mock Exam Information about the mock exam 0.4.5 Exam Information about the exam 0.5 Jamovi statistical software Introduction to Jamovi, and why we are using it instead of other software. 0.6 Textbooks Introduction to the primary textbook Learning statistics with jamovi, and a mention of other sources. 0.7 Canvas How we will use Canvas, and how this book relates to it (Learning and Teaching content, where lectures, assessments, and discussions can be found). 0.8 Timetable "],["week-1-overview.html", "Week 1 Overview", " Week 1 Overview In week 1, we will focus on a refresher of some necessary background mathematics for this module. We will then turn to the topic of how to organise data sets. We will then practice organising datasets and saving them in a usable format. Week: 1 Dates: Suggested Readings: Textbook intro, Hadley’s paper Assessments: Practice quiz Practical: Quick summary of topics covered "],["background_mathematics.html", "Chapter 1 Background mathematics 1.1 Numbers and operations 1.2 Order of operations", " Chapter 1 Background mathematics Some of this will be review, but it is important. Suggested reading for this (some mathematics text). 1.1 Numbers and operations A very broad reminder of mathematics, which you will need for this module 1.2 Order of operations This is easy to forget "],["data_organisation.html", "Chapter 2 Data organisation 2.1 Tidy data 2.2 Data files", " Chapter 2 Data organisation It is important to organise data properly so that statistical analysis can be done. Here I explain the tidy approach to data. Suggested reading Hadley Wickam’s paper. 2.1 Tidy data 2.2 Data files "],["practical-preparing-real-datasets.html", "Chapter 3 Practical: Preparing real datasets 3.1 LibreOffice Calc 3.2 Exercise Organising data 1 3.3 Exercise Organising data 2 3.4 Exercise Organising data 3 3.5 Summary of exercises and why they are useful.", " Chapter 3 Practical: Preparing real datasets In this practical, we will use a spreadsheet to organise datastes. 3.1 LibreOffice Calc LibreOffice Calc is a free and open source spreadsheet program. The instructions for this section will be identical to the more popular commercial Microsoft Excel. 3.2 Exercise Organising data 1 Walks through Exercise 1.3.2 3.3 Exercise Organising data 2 Walks through Exercise 1.3.3 3.4 Exercise Organising data 3 Walks through Exercise 1.3.4, saving all of these as CSV files 3.5 Summary of exercises and why they are useful. "],["week-2-overview.html", "Week 2 Overview", " Week 2 Overview Dates 30 January 2023 - 3 February 2023 Reading Required: SCIU4T4 Workbook chapters 4-8 Recommended: Navarro and Foxcroft (2022) Section 3.3-3.9 Optional: Rowntree (2018) Chapter 2 Advanced: Spiegelhalter (2019) Chapters 1-3 Lectures 2.0: Introduction to Week 1 (2 min.) 2.1: Why study statistics? (18 min.) 2.2: Populations and samples (7 min.) 2.3: Types of variables (11 min.) 2.4: Units, precision, and accuracy (9 min.) 2.5. Uncertainty propagation (11 min.) Practical Introduction to Jamovi Assessments Week 2 Practice quiz on Canvas In Chapter 4, we focus on key concepts that will be used throughout this module. In particular, it is important to understand the difference between a population and a sample, and to recognise that there are many types of variables in statistics. In Chapter 5, we look at different variable types. Different types of variables have different characteristics, which will affect how these variables are best visualised in figures and analysed with statistical hypothesis tests introduced later in the semester. Identifying variable types will therefore be important, both for module assessments and when working with new datasets. A variable’s type will rarely be stated explicitly when doing scientific research, and will not always be provided in assessments for this module. Being able to infer variable type is therefore an important skill. Chapter 6 focus on units of measurement, and how these units are communicated in text. Units are essential in scientific measurement, and we will use them throughout the module to indicate the type and scale of data measurement. We are not expecting you to memorise all scientific units, so a table on units is provided at the end of this workbook. Chapter 7 will introduce the propogation of measurement errors. This is important to understand because no measurement is perfectly accurate, and predicting how errors in measurement combine is fundamental to understanding measurement accuracy. Finally, Chapter 8 guides you through the Week 2 practical, which is an introduction to Jamovi. This aim of this practical is to become familiar with the Jamovi interface and comfortable importing data into Jamovi to collect some descriptive statistics. References "],["Chapter_4.html", "Chapter 4 Populations and samples", " Chapter 4 Populations and samples When we collect data, we are recording some kind of observation or measurement. If we are working in a forest, for example, we might want to measure the heights of different trees, or measure the concentration of carbon in the soil. The idea might be to use these measurements to make some kind of inference about the forest. But as scientists, we are almost always limited in the amount of data that we can collect. We cannot measure everything, so we need to collect a sample of data and use it to make inferences about the population of interest. For example, while we probably cannot measure the height of every tree in a forest, nor can we measure the concentration of carbon at every possible location in the forest’s soil, we can collect a smaller number of measurements and still make useful conclusions about overall forest trees and carbon concentration. Statistics thereby allows us to approximate properties of entire populations from a limited number of samples. This needs to be done with caution, but before getting into the details of how, it is important to understand the difference between a population and a sample to avoid confusing these two concepts. A population is the entire set of possible observations that could be collected. Some examples will make it easier to understand: All of the genes in the human genome All individuals of voting age in Scotland All common pipistrelle bats in the United Kingdom These populations might be important for a particular research question. For example, we might want to know something about the feeding behaviours of pipistrelle bats in the UK. But there is no way that we can find and observe the behaviour of every bat, so we need to take a subset of the population (a sample) instead. Examples of samples include the following: A selection of 20 human genes A pub full of Scottish voters 40 caught common pipistrelle bats It is important to recognise that the word “population” means something slightly different in statistics than it does in biology. A biological population, for example, could be defined as all of the individuals of the same species in the same general location. A statistical population, in contrast, refers to a set of observations (i.e., things that we can measure). Sokal and Rohlf (1995) provide a more technical definition for “population”, In statistics, population always means the totality of individual observations about which inferences are to be made, existing anywhere in the world or at least within a definitely specified sampling area limited in space and time [p. 9, emphasis theirs]. They define a sample to be “a collection of individual observations selected by a specified procedure” (Sokal and Rohlf 1995). For our purposes, it is not necessary to be able to recite the technical definitions, but it is important to understand the relationship between a population and a sample. When we collect data, we are almost always taking a small sample of observations from a much larger number of possible observations in a population. Figure 4.1: A conceptual figure illustrating how a statistical population relates to a statistical sample. The population is represented by 35 smiling faces enclosed within a dashed box. The sample is represented by a solid box within the dashed box, within which there are 3 smiling faces. Hence, we have a sample of 3 measurements from the total population. References "],["Chapter_5.html", "Chapter 5 Types of variables", " Chapter 5 Types of variables A variable is any property that is measured in an observation (Sokal and Rohlf 1995); i.e., anything that varies among things that we can measure (Dytham 2011). We can summarise how these measurements vary with summary statistics, or visually with figures. Often, we will want to predict one variable from a second variable. In this case, the variable that we want to predict is called the response variable, also known as the dependent variable or Y variable (‘dependent’ because it depends on other variables, and ‘Y’ because this is the letter we often use to represent it). The variable that we use to predict our response variable is the explanatory variable, also known as the independent variable or X variable (‘independent’ because it does not depend on other variables, and ‘X’ because this is the letter most often used to represent it). There are several different types of variables: Categorical variables take on a fixed number of discrete values (Spiegelhalter 2019). In other words, the measurement that we record will assign our data to a specific category. Examples of categorical variables include species (e.g., “Robin”, “Nightingale”, “Wren”) or life history stage (e.g., “egg”, “juvenile”, “adult”). Categorical variables can be either nominal or ordinal. Nominal variables do not have any inherent order (e.g., classifying land as “forest”, “grassland”, or “urban”). Ordinal variables do have an inherent order (e.g., “low”, “medium”, and “high” elevation). Quantitative variables are variables represented by numbers that reflect a magnitude. That is, unlike categorical variables, we are collecting numbers that really mean something tangible (in contrast, while we might represent low, medium, and high elevations with the numbers 1, 2, and 3, respectively, this is just for convenience; a value of ‘2’ does not always mean ‘medium’). Categorical variables can be either discrete or continuous. Discrete variables can take only certain values. For example, if we want to record the number of species in a forest, then our variable can only take discrete counts (i.e., integer values). There could conceivably be any whole number of species (1, 2, 3, etc.), but there could not be 2.51 different species in a forest; that does not make sense. Continuous variables can take any real value within some range of values (i.e., any number that can be represented by a decimal). For example, we could measure height to as many decimals as our measuring device will allow, with a range of values from zero to the maximum possible height of whatever it is we are measuring. Similarly, we could measure temperature to any number of decimals, at least in theory, so temperature is a continuous variable. The reason for organising variables into all of these different types is that different types of variables need to be handled in different ways. For example, it would not make sense to visualise a nominal variable in the same way as a continuous variable. Similarly, the choice of statistical test to apply to answer a statistical question will almost always depend on the types of variables involved. If presented with a new data set, it is therefore very important to be able to interpret the different variables and apply the correct statistical techniques (this will be part of the assessment for this module). References "],["Chapter_6.html", "Chapter 6 Accuracy, precision, and units 6.1 Accuracy 6.2 Precision 6.3 Systems of units 6.4 Other examples of units", " Chapter 6 Accuracy, precision, and units The science of measurements is called “metrology”, which, among other topics, focuses on measurement accuracy, precision, and units (Rabinovich 2013). We will not discuss these topics in depth, but they are important for statistical techniques because measurement, in the broadest sense of the word, is the foundation of data collection. When collecting data, we want measurements to be accurate, precise, and clearly defined. 6.1 Accuracy When we collect data, we are trying to obtain information about the world. We might, for example, want to know the number of seedlings in an area of forest, them temperature of the soil at a location, or the mass of a particular animal in the field. To get this information, we need to make measurements. Some measurements can be collected by simple observation (e.g., counting seedlings), while others will require measuring devices such as a thermometer (for measuring temperature) or scale (for measuring mass). All of these measurements are subject to error. The true value of whatever it is that we are trying to measure (called the “measurand”) can differ from what we record when collecting data. This is true even for simple observations (e.g., we might miscount seedlings), so it is important to recognise that the data we collect comes with some uncertainty. The accuracy of a measurement is defined by how close the measurement is to the true value of what we are trying to measure (Rabinovich 2013). 6.2 Precision The precision of a measurement is how consistent it will be if measurement is replicated multiple times. In other words, precision describes how similar measurements are expected to be. If, for example, a scale measures an object to be the exact same mass ever time it is weighed (regardless of whether the mass is accurate), then the measurement is highly precise. If, however, the scale measures a different mass each time the object is weighed (for this hypothetical, assume that the true mass of the object does not change), then the measurement is not as precise. One way to visualise the difference between accuracy and precision is to imagine a set of targets, with the centre of the target representing the true value of what we are trying to measure (Figure 6.1)1. Figure 6.1: A conceptual figure illustrating the difference between accuracy and precision. Points in (A) are both accurate and precise, points in (B) are accurate, but not precise, points in (C) are precise but not accurate, and points in (D) are neither accurate nor precise. Note again that accuracy and precision are not necessarily the same. Measurement can be accurate but not precise (Figure 6.1B) or precise but not accurate (Figure 6.1C). 6.3 Systems of units Scientific units are standardised with the Système International D’Unités (SI). Having standardised units of measurement is highly important to ensure measurement accuracy (Quinn 1995). Originally, these units were often defined in terms of physical artefacts. For example, the kilogram (kg) was once defined by physical cylinder metal housed in the Buereau International des Poids et Mesures (BIPM). In other words, the mass of a metal sitting at the BIPM defined what a kg was, with the mass of every other measurement being based on this physical object (Quinn 1995). This can potentially present a problem if the mass of that one object changes over time, thereby causing a change in how a kg is defined. Where possible, it is therefore preferable to define units in terms of fundamental constants of nature. In 2019, for example, the kg was redefined in terms of the Planck constant, a specific atomic transition frequency, and the speed of light (Stock et al. 2019). This ensures that measurements of mass remain accurate over time because what a kg represents in terms of mass cannot change. We can separate units into base units and derived units. Table 6.1 below lists some common base units for convenience (Quinn 1995). You do not need to memorise these units, but it is good to be familiar with them. We will use these units throughout the module. Base units of SI measurements. For details see Quinn (1995). Measured Quantity Name of SI unit Symbol Mass kilogram \\(kg\\) Length metre \\(m\\) Time second \\(s\\) Electric current ampere \\(A\\) Temperature kelvin \\(K\\) Amount of a substance mole \\(mol\\) Luminous intensity candela \\(cd\\) We can also define derived SI units from the base units of Table 6.1; examples of these derived SI units are provided in Table 6.2 below. Again, you do not need to memorise these units, but it is good to be aware of them. Examples of derived SI units. Measured Quantity Name of unit Symbol Definition in SI units Alternative in derived units Energy Joule \\(J\\) \\(m^{2}\\) \\(kg\\) \\(s^{-2}\\) \\(N\\) \\(m\\) Force Newton \\(N\\) \\(m\\) \\(kg\\) \\(s^{-2}\\) \\(J\\) \\(m^{-1}\\) Pressure Pascal \\(Pa\\) \\(kg\\) \\(m^{-1}\\) \\(s^{-2}\\) \\(N\\) \\(m^{-2}\\) Power Watt \\(W\\) \\(m^{-2}\\) \\(kg\\) \\(s^{-3}\\) \\(J\\) \\(s^{-1}\\) Frequency Hertz \\(Hz\\) \\(s^{-1}\\) Radioactivity Becquerel \\(Bq\\) \\(s^{-1}\\) When numbers are associated with units, it is important to recognise that the units must be carried through and combined when calculating equation. As a very simple example, if want to know the speed at which an object is moving, and we find that it has moved 10 metres in 20 seconds, then we calculate the speed and report the correct units as below, \\[speed = \\frac{10\\:m}{20\\:s} = 0.5\\:m/s = 0.5\\:m\\:s^{-1}.\\] Notice that the final units are in metres per second, which can be written as \\(m/s\\) or \\(m\\:s^{-1}\\) (remember that raising \\(s\\) to the \\(-1\\) power is the same as \\(1/s\\); see below for a quick reminder about superscripts). It is a common error to calculate just the numeric components of a calculation and ignore the associated units. Often on assessments, we will ask you not to include units in your answer (this is just for convenience on the tests and exam), but recognising that units are also part of calculations is important. 6.4 Other examples of units Remember that an exponent (indicated by a superscript, e.g., the 3 in \\(m^{3}\\)) indicates the number of times to multiply a base by itself, so \\(m^{3} = m \\times m \\times m\\). 6.4.1 Units of density Density (\\(\\rho\\)) is calculated by, \\[\\rho = \\frac{mass}{volume} = \\frac{kg}{m^{3}}.\\] The units of density are therefore mass per unit volume, \\(kg\\:m^{-3}\\). 6.4.2 Mass of metal discharged from a catchment The mass of metal carried by a stream per unit time (\\(M\\)) is given by multiplying the concentration of metal per unit volume (\\(C\\)) of water by the volume of water discharged per unit time (\\(V\\)), \\[M = C \\times V.\\] This equation is useful in showing how units can cancel each other out. If we calculate the above with just the units (ignoring numbers for \\(C\\) and \\(V\\)), \\[M = \\frac{mg}{l} \\times \\frac{l}{s} = \\frac{mg}{s}.\\] Notice above how the \\(l\\) units on the top and bottom of the equation cancel each other out, so we are left with just \\(mg/s\\). 6.4.3 Soil carbon inventories For one final example, the inventory of carbon \\(I\\) within a soil is given by the specific carbon concentration \\(C\\) (\\(g\\) of carbon per \\(kg\\) of soil), multiplied by the depth of soil analysed (\\(D\\), \\(m\\)), and by the density (\\(\\rho\\), \\(kg\\:m^{-3}\\)), \\[I = C \\times D \\times \\rho = \\frac{g\\times m \\times kg}{kg \\times m^{3}} = \\frac{g}{m^{2}} = g\\:m^{-2}.\\] Notice above how the \\(kg\\) on the top and bottom of the fraction cancel each other out, and how one \\(m\\) on the top cancels out one \\(m\\) on the bottom, so that what we are left with is grams per metre squared (\\(g\\:m^{-2}\\)). References "],["Chapter_7.html", "Chapter 7 Uncertainty propogation 7.1 Adding or subtracting errors 7.2 Multiplying or dividing errors 7.3 Applying formulas for combining errors", " Chapter 7 Uncertainty propogation Nothing can be measured with perfect accuracy, meaning that every measurement has some associated error. The measurement error might be caused by random noise in the measuring environment, or by mistakes made by the person doing the measuring. The measurement error might also be caused by limitations or imperfections associated with a measuring device. The device might be limited in its measurement precision, or perhaps it is biased in its measurements due to improper calibration, manufacture, or damage from previous use. All of this generates uncertainty with respect to individual measurements. Recall from Chapter 6 the difference between precision and accuracy. We can evaluate the precision and accuracy of measurements in different ways. Measurement precision can be estimated by replicating a measurement (i.e., taking the same measurement over and over again). The more replicate measurements made, the more precisely a value can be estimated. For example, if we wanted to evaluate the precision with which the mass of an object is measured, then we might repeat the measurement with the same scale multiple times and see how much mass changes across different measurements. To evaluate measurement accuracy, we might need to measure a value in multiple different ways (e.g., with different measuring devices). For example, we might repeat the measurement of an object’s mass with a different scale. Sometimes it is necessary to combine different values. For example, we might measure the mass of 2 different bird eggs in a nest, then calculate the total mass of all the 2 eggs combined. The measurement of each egg will have its own error, and these errors will propagate to determine the error of the total egg mass for the nest. How this error propagates differs depending on if they are being added or subtracted, or if they are being multiplied or divided. 7.1 Adding or subtracting errors In the case of our egg masses, we can assign the mass of the first egg to the variable \\(X\\) and the mass of the second egg to the variable \\(Y\\). We can assign the total mass to the variable \\(Z\\), where \\(Z = X + Y\\). The errors associated with the variables \\(X\\), \\(Y\\), and \\(Z\\) can be indicated by \\(E_{X}\\), \\(E_{Y}\\), and \\(E_{Z}\\), respectively. In general, if the variable \\(Z\\) is calculated by adding (or subtracting) 2 or more values together, then this is the formula for calculating \\(E_{Z}\\), \\[E_{Z} = \\sqrt{E^{2}_{X} + E^{2}_{Y}}.\\] Hence, for the egg masses, the error of the combined masses () equals the square root of the error associated with the mass of egg 1 squared (\\(E^{2}_{X}\\)) plus the error associated with the mass of egg 2 squared (\\(E^{2}_{Y}\\)). It often helps to provide a concrete example. If the error associated with the measurement of egg 1 is \\(E^{2}_{X} = 2\\), and the error associated with the measurement of egg 2 is \\(E^{2}_{X} = 3\\), then we can calculate, \\[E_{Z} = \\sqrt{2^{2} + 3^{2}} \\approx 3.61.\\] 7.2 Multiplying or dividing errors Multiplying or dividing errors works a bit differently. As an example, suppose that we need to measure the total area of a rectangular field. If we measure the length (\\(L\\)) and width (\\(W\\)) of the field, then the total area is the product of these measurements, \\(A = L \\times W\\). Again, there is going to be error associated with the measurement of both length (\\(E_{L}\\)) and width (\\(E_{W}\\)). How the error of the total area (\\(E_{A}\\)) is propagated by \\(E_{L}\\) and \\(E_{W}\\) is determined by the formula, \\[E_{A} = A \\sqrt{\\left(\\frac{E_{L}}{L} \\right)^{2} + \\left(\\frac{E_{W}}{W} \\right)^{2}}.\\] Notice that just knowing the error of each measurement (\\(E_{L}\\) and \\(E_{W}\\)) is no longer sufficient to calculate the error associated with the measurement of the total area. We also need to know \\(L\\), \\(W\\), and \\(A\\). If our field has a length of \\(L = 20\\) m and width of \\(W = 10\\), then \\(A = 20 \\times 10 = 200\\). If length and width measurements have associated errors of \\(E_{L} = 2\\) m \\(E_{W} = 1\\) m, then, \\[E_{A} = 200 \\sqrt{\\left(\\frac{2}{20} \\right)^{2} + \\left(\\frac{1}{10} \\right)^{2}} \\approx 28.3.\\] Of course, not every set of measurements with errors to be multiplied with be lengths and widths. To avoid confusion, the general formula for multiplying or dividing errors is below, with the variables \\(L\\), \\(W\\), and \\(A\\) replaced with \\(X\\), \\(Y\\), and \\(Z\\), respectively, to match the case of addition and subtraction explained above, \\[E_{Z} = Z \\sqrt{\\left(\\frac{E_{X}}{X} \\right)^{2} + \\left(\\frac{E_{Y}}{Y} \\right)^{2}}.\\] Note that the structure of the equation is the exact same, just with different letters used as variables. It is necessary to be able to apply these equations correctly to estimate combined error. 7.3 Applying formulas for combining errors It is not necessary to understand why the equations for propagating different types of errors are different, but a derivation is provided in Appendix B for the curious. "],["Chapter_8.html", "Chapter 8 Practical. Introduction to Jamovi 8.1 Exercise for summary statistics 8.2 Exercise on transforming variables 8.3 Exercise on computing variables", " Chapter 8 Practical. Introduction to Jamovi This practical focuses on learning how to work with datasets in Jamovi. Jamovi is available in the university laboratory computers through AppsAnywhere. You can also download it on your own computer for free or run it directly from a browser. For an introduction to what Jamovi is and why we are using it in this module, see Section 0.5 of this workbook and Sections 3.3-3.9 of Navarro and Foxcroft (2022). In this module, we will work with two datasets, both of which are based on real biological and environmental studies conducted by researchers at the University of Stirling. The first dataset includes measurements of soil organic carbon (grams of Carbon per kg of soil) from the topsoil and subsoil collected in a national park in Gabon. These data were collected by Dr Carmen Rosa Medina-Carmona in an effort to understand how pyrogenic carbon (i.e., carbon produced by the charring of biomass during a fire) is stored in different landscape areas (Santín et al. 2016; Preston and Schmidt 2006). Download these data here: soil_organic_carbon.csv The second dataset includes measurements of figs from trees of the Sonoran Desert Rock Fig (Ficus petiolaris) in Baja, Mexico. These data were collected by Dr Brad Duthie in an effort to understand coexistence in a fig wasp community (Duthie, Abbott, and Nason 2015; Duthie and Nason 2016). Measurements include fig lengths, widths, and heights in centimeters from 4 different fig trees, and the number of seeds in each fruit. Download these data here: fig_fruits.csv Figure 8.1: Three images showing the process of collecting data for the dimensions of figs from trees of the Sonoran Desert Rock Fig in Baja, Mexico. (A) Processing fig fruits, which included measuring the diameter of figs along three diferent axes of length, width, and height, (B) a fig still attached to a tree with a fig wasp on top of it, and (C) a sliced open fig with seeds along the inside of it. This lab will use the soil organic carbon dataset in Exercise 8.1 for summary statistics. The fig fruits will be used for Exercise 8.2 on transforming variables and Exercise 8.3 on computing a variable. 8.1 Exercise for summary statistics Download the soil organic carbon dataset if you have not already done so, and save it in a location where you know you will be able to find it again, then open Jamovi. Once Jamovi is open, you can import the dataset by clicking on the three lines in the upper left corner of the tool bar, then selecting ‘Open’ (Figure 8.2). Figure 8.2: The Jamovi toolbar including tabs for opening files, Variables, Data, Analyses, and Edit. To open a file, select the three horizontal lines in the upper right You might need to click ‘Browse’ in the upper right of Jamovi to find the file. Figure 8.3 below shows how this will look when you browse for a data file. Figure 8.3: The Jamovi interface for opening a file with the ‘Import’ tab selected. Options for browsing to a file on the computer are available in the upper right, which opens the window in the foreground. Once the data are imported, you should see two separate columns. The first column will show soil organic carbon values for topsoil samples, and the second column will show soil organic carbon values for subsoil samples. Notice right away that these data are not formatted in a tidy way. We need to fix this so that each row is a unique sample, and each column represents some property of the sample (see the previous chapter section on data organisation for a reminder of why). It might be easiest to reorganise the data in a spreadsheet such as LibreOffice Calc or Microsoft Excel. But you can also edit the directly in Jamovi by clicking on the ‘Data’ tab in the toolbar (see Figure 8.2). The best way to reorganise the data in Jamovi is to double-click on the third column of data next to ‘subsoil’ (see Figure 8.4). Figure 8.4: The Jamovi toolbar is shown with the soil organic carbon dataset. In Jamovi, double-clicking above column three where it says ‘CLICK HERE’ will allow you to input a new variable. After double-clicking on the location shown in Figure 8.4, there will be three buttons visible. You can click the ‘New Data Variable’ to insert a new variable named ‘soil_type’ in place of the default name ‘C’. Keep the ‘Measure type’ as ‘Nominal’, but change the ‘Data type’ to ‘text’. When you are done, click the &gt; character to the right so that the variable is fixed (Figure 8.5). Figure 8.5: The Jamovi toolbar is shown with the input for creating a new data variable. The new variable added is to indicate the soil type (topsoil or subsoil), so it needs to be a nominal variable with a data type of text. After typing in the new variable ‘soil_type’, add another variable called ‘organic_carbon’. The organic_carbon variable should have a measure type of ‘Continuous’ and a data type of ‘Decimal’. After both soil_type and organic_carbon variables have been set, you can click the up arrow with the upper right circle (Figure 8.5) to get the new variable window out of the way. With the two new variables created, we can now rearrange the data in a tidy way. The first 19 rows of soil_type should be ‘topsoil’, and the remaining 15 rows should be ‘subsoil’. To do this quickly, you can write ‘topsoil’ in the first row of soil_type and copy-paste into the remaining rows. You can do the same to write ‘subsoil’ in the remaining rows 20-34. Next, copy all of the topsoil values in column 1 into the first 19 rows of column 4, and copy all of the subsoil values in column 2 into the next 15 rows. After doing all of this, you column 3 (soil_type) should have the word ‘topsoil’ in rows 1-19 and ‘subsoil’ in rows 20-34. The values from columns 1 and 2 should now fill rows 1-34 of column 4. You can now delete the first column of data by right clicking on the column name ‘topsoil’ and selecting ‘Delete Variable’. Do the same for the second column ‘subsoil’. Now you should have a tidy data set with two columns of data, one called ‘soil_type’ and one called ‘organic_carbon’. You are now ready to calculate some descriptive statistics from the data. First, we can calculate the minimum, maximum, and mean of all of the organic carbon values. To do this, select the ‘Analyses’ tab, then click on the left-most button called ‘Exploration’ in the toolbar (Figure 8.6). Figure 8.6: The Jamovi toolbar where the tab ‘Analyses’ can be selected at the very top. Below this tab, the button ‘Exploration’ can be clicked to calculate descriptive statistics. After clicking on ‘Exploration’, a pull-down box will appear with an option for ‘Descriptives’. Select this option, and you will see a new window with our two columns of data in the left-most box. Click once on the ‘organic_carbon’ variable and use the right arrow to move it into the ‘Variables’ box. In the right-most panel of Jamovi, a table called ‘Descriptives’ will appear, which will include values for the organic carbon mean, minimum, and maximum. Write these values on the lines below, and remember to include units. Mean: ____________________________ Minimum: ____________________________ Maximum: ____________________________ These values might be useful, but recall that there are two different soil types that need to be considered, topsoil and subsoil. The mean, minimum, and maximum above pools both of these soil types together, but we might instead want to know the mean, minimum, and maximum values for topsoil and subsoil separately. Splitting organic carbon by soil types is straightforward in Jamovi. To do it, go back to the Exploration \\(\\to\\) Descriptives option and again put ‘organic_carbon’ in the Variables box. This time, however, notice the ‘Split by’ box below the Variables box. Now, click on ‘soil_type’ in the descriptives and click on the lower right arrow to move soil type into the ‘Split by’ box. The table of descriptives in the right window will now break down all of the summary statistics by soil type. First, write the mean, minimum, and maximum topsoil values below. Mean: ____________________________ Minimum: ____________________________ Maximum: ____________________________ Next, do the same for the mean, minimum, and maximum subsoil values. Mean: ____________________________ Minimum: ____________________________ Maximum: ____________________________ From the values above, the mean of organic carbon sampled from the topsoil appears to be greater than the mean of organic carbon sampled from the subsoil. Assuming that Jamovi has calculated the means correctly, we can be confident that the topsoil sample mean is higher. But what about the population means? Think back to concepts of populations versus samples from Chapter 4. Based on these samples in the dataset, can we really say for certain that the population mean of topsoil is higher than the population mean of subsoil? Think about this, then write a sentence below about how confident we can be about concluding that topsoil organic carbon is greater than subsoil organic carbon. What would make you more (or less) confident that topsoil and subsoil population means are different? Think about this, then write another sentence below that answers the question. Note that there is no right or wrong answer for the above two questions. The entire point of the questions is to help you reflect on your own learning and better link the concepts of populations and samples to the real dataset in this practical. Doing this will make the statistical hypothesis testing that comes later in the module more clear. 8.2 Exercise on transforming variables In this next exercise, we will work with the fig fruits dataset. Open this dataset into Jamovi. Note that there are five columns of data, and all of the data appear to be in a tidy format. Each row represents a separate fig fruit, while each column represents a measured variable associated with the fruit. The first several rows should look like the below. ## Tree Length_cm Width_cm Height_cm Seeds ## 1 A 1.5 1.8 1.4 238 ## 2 A 1.7 1.9 1.5 198 ## 3 A 2.1 2.1 1.6 220 ## 4 A 1.5 1.6 1.4 188 ## 5 A 1.6 1.6 1.5 139 ## 6 A 1.5 1.4 1.5 173 The dataset includes the tree from which the fig was sampled in column 1 (A, B, C, and D), then the length, width, and heights of the fig in cm. Finally, the last column shows how many seeds were counted within the fig. Use the Descriptives option in Jamovi to find the overall (i.e., not split by Tree) mean length, width, and height of figs in the dataset. Write these means down below (remember the units). Mean length: ____________________________ Mean height: ____________________________ Mean width: ____________________________ Now look at the different rows in the Descriptives table of Jamovi. Note that there is a row for ‘Missing’, and there appears to be one missing value for fig width and fig height. This is very common in real datasets. Sometimes practical limitations in the field prevent data from being collected, or something happens that causes data to be lost. We therefore need to be able to work with datasets that have missing data. For now, we will just note the missing data and find them in the actual data set. Go back to the ‘Data’ tab in Jamovi and find the figs with a missing width and height value. Report the rows of these missing values below. Missing width row: ____________________________ Missing height row: ____________________________ Next, we will go back to working with the actual data. Note that the length, width, and height variables are all recorded in cm to a single decimal place. Suppose we want to transform these variables so that they are represented in mm instead of cm. We will start by creating a new column ‘Length_mm’ by transforming the existing ‘Length_cm’ column. To do this, click on the ‘Data’ tab at the top of the toolbar again, then click on the ‘Length_cm’ column name to highlight the entire column. Your screen should look like the image in Figure 8.7. Figure 8.7: The Jamovi toolbar where the tab ‘Data’ is selected. The length (cm) column is highlighted and will be transformed by clicking on the Transform button in the toolbar above With the ‘Length_cm’ column highlighted, click on the ‘Transform’ button in the toolbar. Two things happen next. First, a new column appears in the dataset that looks identical to ‘Length_cm’; ignore this for now. Second, a box appears below the toolbar allowing us to type in a new name for the transformed variable. We can call this variable ‘Length_mm’. Below, note the first pulldown menu ‘Source variable’. The source value should be ‘Length_cm’, so we can leave this alone. The second pulldown menu ‘using transform’ will need to change. To change the transform from ‘None’, click the arrow and select ‘Create New Transform’ from the pulldown. A new box will pop up allowing us to name the transformation. It does not matter what we call it (e.g., ‘cm_to_mm’ is fine). Note that there are 10 mm in 1 cm, so to convert from cm to mm, we need to multiply the values of ‘Length_cm’ by 10. We can do this by appending a * 10 to the lower box of the transform window, so that it reads = $source * 10 (Figure 8.8). Figure 8.8: The Jamovi toolbar where the tab ‘Data’ is selected. The box below shows the transform, which has been named ‘cm to mm’. The transformation occurs by multiplying the source (Length mm) by 10. The dataset underneath shows the first few rows with the transformed column highlighted (note that the new ‘Length mm’ column is 10 times the length column. When we are finished, we can click the down arrow inside the circle in the upper right to get rid of the transform window, then the up arrow inside the circle in the upper right to get rid of the transformed variable window. Now we have a new column called ‘Length_mm’, in which values are 10 times greater than they are in the adjacent ‘Length_cm’ column, and therefore represent fig length in mm. If we want to, we can always change the transformation by double-clicking the ‘Length_mm’ column. For now, apply the same transformation to fig width and height, so we have three new columns of length, width, and height all measured in mm (note, if you want to, you can use the saved transformation ‘cm_to_mm’ that you used to transform length, saving some time). At the end of this, you should have eight columns of data, including three new columns that you just created by transforming the existing columns of Length_cm, Width_cm, and Height_cm into the new columns Length_mm, Width_mm, and Height_mm. Find the means of these three new columns and write them below. Mean length: ____________________________ Mean height: ____________________________ Mean width: ____________________________ Compare these means to the means calculated above in cm. Do the differences between means in cm and the means in mm make sense? 8.3 Exercise on computing variables In this last exercise, we will compute a new variable ‘fig_volume’. Because of the way that the dimensions of the fig were measured in the field, we need to make some simplifying assumptions when calculating volume. We will assume that fig fruits are perfect spheres, and that the radius of each fig is half of its measured width (i.e., ‘Width_mm / 2’). This is obviously not ideal, but sometimes practical limitations in the field make it necessary to make these kinds of simplifying assumptions. In this case, how might assuming that figs are perfectly spherical affect the accuracy of our estimated fig volume? Write a sentence of reflection on this question below, drawing from what you have learned this week about accuracy and precision of measurements. Now we are ready to make our calculation of fig volume. The formula for the volume of a sphere (\\(V\\)) given its radius \\(r\\) is, \\[V = \\frac{4}{3} \\pi r^{3}.\\] In words, sphere volume equals four thirds times \\(\\pi\\), times \\(r\\) cubed (i.e., to the third power). If this equation is confusing, remember that \\(\\pi\\) is approximately 3.14, and taking \\(r\\) to the third power means that we are multiplying \\(r\\) by itself 3 times. We could therefore rewrite the equation above, \\[V = \\frac{4}{3} \\times 3.14 \\times r \\times r \\times r.\\] This is the formula that we can use to create our new column of data for fig volume. To do this, click on the first empty column of the dataset, just to the right of the ‘Seeds’ column header. You will see a pull down option in Jamovi with 3 options, one of which is ‘NEW COMPUTED VARIABLE’. This is the option that we want. We need to name this new variable, so we can call it ‘fig_volume’. Next, we need to type in the formula for calculating volume. First, in the small box next to the \\(f_{x}\\), type in the (4/3) multiplied by 3.14 as below. = (4/3) * 3.14 * Next, we need to multiply by the variable ‘Width_mm’ divided by 2 (to get the radius), three times. We can do this by clicking on the \\(f_{x}\\) box to the left. Two new boxes will appear; the first is named ‘Functions’, and the second is named ‘Variables’. Ignore the functions box for now, and find ‘Width_mm’ in the list of variables. Double click on this to put it into the formula, then divide it by 2. You can repeat this two more times to complete the computed variable as shown in Figure 8.9. Figure 8.9: The Jamovi toolbar where the tab ‘Data’ is selected. The box below shows the new computed variable ‘fig volume’, which has been created by calculating the product of 4/3, 3.14, and Width mm three times. Note that we can get the cube of ‘Width_mm’ more concisely by using the carrot character (^). That is, we would get the same answer shown in Figure 8.9 if we instead typed the below in the function box. = (4/3) * 3.14 * (Width_mm/2)^3 Note that the order of operations is important here, which is why there are parentheses around Width_mm/2. This calculation needs to be done before taking the value to the power of 3. If we instead had written, Width_mm/2^3, the Jamovi would first take the cube of 2 \\((2 \\times 2 \\times 2 = 8)\\), then divided Width_mm by this value giving a different and incorrect answer. When in doubt, it is always useful to use parentheses to specify what calculations should be done first. You now have the new column of data ‘fig_volume’. Remember that the calculations underlying this new variable need to be done for the units. The width of the fig was calculated in mm, but we have taken width to the power of 3 when calculating the volume. In the spaces below, find the overall mean, minimum, and maximum volumes of figs and report them in the correct units. Mean: ____________________________ Minimum: ____________________________ Maximum: ____________________________ Finally, it would be good to plot these newly calculated fig volume data. These data are continuous, so we can use a histogram to visualise the fig volume distribution. To make a histogram, go to the Exploration \\(\\to\\) Descriptives window in Jamovi (the same place where you found the mean, minimum, and maximum). Now, look on the lower left-hand side of the window and find the pulldown menu for ‘Plots’. Click ‘Plots’, and you should see several different plotting options. Check the option for ‘Histogram’ and see the new histogram plotted in the window to the right. Draw a rough sketch of the histogram in the area below. References "],["week-3-overview.html", "Week 3 Overview", " Week 3 Overview Dates 6 February 2023 - 10 February 2023 Reading Required: SCIU4T4 Workbook chapters 9-12 Recommended: Navarro and Foxcroft (2022) Chapter 5 and Chapter 4.1 Optional: Rowntree (2018) Chapter 3 Lectures 3.0: Decimal places and significant figures part 1 (8 min.) 3.1: Decimal places and significant figures part 2 (7 min.) 3.2: Graphs (11 min.) 3.3: Box-whisker plots (8 min.) 3.4: The mean (17 min.) 3.5: The mode (7 min.) 3.6: The median and quantiles (8 min.) 3.7: Mean, mode, median, and resistance (9 min.) Practical Plotting and statistical summaries Assessments Week 3 Practice quiz on Canvas References "],["Chapter_9.html", "Chapter 9 Decimal places, significant figures, and rounding 9.1 Decimal places and significant figures 9.2 Rounding", " Chapter 9 Decimal places, significant figures, and rounding When making calculations, it is important that any numbers reported are communicated with accuracy and precision. This means reporting numbers with the correct number of digits. This chapter focuses on correctly interpreting the decimal places and significant figures of a number, and correctly rounding. In your assessments, you will frequently be asked to report an answer to a specific number of decimal places or significant figures, and you will be expected to round numbers correctly. 9.1 Decimal places and significant figures A higher number of digits communicates a greater level of accuracy For example, the number 2.718 expresses a higher precision than 2.7 does. Reporting 2.718 implies that we know the value is somewhere between 2.7175 and 2.1785, but reporting 2.7 only implies that we know the value is somewhere between 2.65 and 2.75 (Sokal and Rohlf 1995). These numbers therefore have a different number of decimal places and a different number significant figures. Decimal places and significant figures are related, but not the same. Decimal places are conceptually easier to understand. These are just the number of digits to the right of the decimal point. For example, 2.718 has 3 decimal places and 2.7 has 1 decimal place. Significant figures are a bit more challenging. These are the number of digits that you need to infer the accuracy of a value. For example, the number 2.718 has 4 significant figures and 2.7 has 2 significant figures. This sounds straightforward, but it can get confusing when numbers start or end with zeros. For example, the number 0.045 has only two significant figures because the first two zeros only serve as placeholders (note that if this were a measurement of 0.045 m, then we could express the exact same value as 45 mm, so the zeros are not really necessary to indicate measurement accuracy). In contrast, the measurement 0.045000 has 5 significant figures because the last 3 zeros indicate a higher degree of accuracy than just 0.045 would (i.e., we know the value is somewhere between 0.44995 and 0.45005, not just 0.0445 and 0.0455). Lastly, the measurement 4500 has only 2 significant figures because the last 2 zeros are only serving as a placeholder to indicate magnitude, not accuracy (if we wanted to represent 4500 with 4 significant figures, we could use scientific notation and express it as \\(4.500 \\times 10^3\\)). Here is a table with some examples of some numbers, their decimal places, and their significant figures. Numbers are presented in rows of the first column. Decimal places and significant figures for each row number are presented in the second and third column, respectively. Number Decimal places Significant figures 3.14159 5 5 0.0333 4 3 1250 0 3 50000.0 1 6 0.12 2 2 1000000 0 1 It is a good idea to double-check that the values in these tables make sense. For assessments, make sure that you are confident that you can report your answer to a given number of decimal places or significant figures. 9.2 Rounding Often if you are asked to report a number to a specific number of decimals or significant figures, you will need to round the number. Rounding reduces the number of significant digits in a number, which might be necessary if a number that we calculate has more significant digits than we are justified in expressing. There are different rules for rounding numbers, but in this module, we will follow Sokal and Rohlf (1995). When rounding to the nearest decimal, the last decimal written should not be changed if the number that immediately follows is 0, 1, 2, 3, or 4. If the number that immediately follows is 5, 6, 7, 8, or 9, then the last decimal written should be increased by 1. For example, if we wanted to round the number 3.141593 to 2 significant digits, then we would write it as 3.1 because the digit that immediately follows (i.e., the third digit) is 4. If we wanted to round the number to 5 significant digits, then we would write it as 3.1415 because the digit that immediately follows is 9. And if we wanted to round 3.141593 to 4 significant digits, then we would write it as 3.146 because the digit that immediately follows is 5. Note that this does not just apply for decimals. If we wanted to round 1253 to 3 significant figures, then we would round by writing it as 1250. Here is a table with some examples of numbers rounded to a given significant figure. Numbers to be rounded are presented in rows of the first column. The significant figures to which rounding is desired is in the second column, and the third column shows the correctly rounded number. Original number Significant figures Rounded number 23.2439 4 23.24 10.235 4 10.24 102.39 2 100 5.3955 3 5.40 37.449 3 37.4 0.00345 2 0.0035 In this module, it will be necessary to round calculated values to specified decimal or significant figure. It is therefore important to understand the rules for rounding and why the values in the table above are rounded correctly. References "],["Chapter_10.html", "Chapter 10 Graphs 10.1 Histograms 10.2 Barplots and pie charts 10.3 Box-whisker plots", " Chapter 10 Graphs Graphs are useful tools for visualising and communicating data. Graphs come in many different types, and different types of graphs are effective for different types of data. This chapter focuses on four types of graphs: (1) histograms, (2) pie charts, (3) barplots, and (4) box-whisker plots. After collecting or obtaining a new dataset, it is almost always a good idea to plot the data in some way. Visualising a dataset can often highlight important and obvious properties of a dataset more efficiently that inspecting raw data, calculating summary statistics, or running statistical tests. When making graphs to communicate data visually, it is important to ensure the person reading the graph has a clear understanding what is being presented. In practice, this means clearly labelling axes with meaningful descriptions and appropriate units, including a descripting caption, and indicating what any graph symbols mean. In general, it is also best to make the simplest graph possible for visualising the data, which means avoiding unnecessary colour, three-dimensional display, or unnecessary distractions from the information being conveyed (Dytham 2011; Kelleher and Wagener 2011). It is also important to ensure that graphs are as accessible as possible, e.g., by providing strong colour contrast and appropriate colour combinations (Elavsky, Bennett, and Moritz 2022), and alternative text for images where possible. As a guide, the histogram, pie chart, barplot, and box-whisker plot below illustrate good practice when making graphs. 10.1 Histograms Histograms illustrate the distribution of continuous data. They are especially useful visualisation tools because it is often important to assess data at a glance and make a decision about how to proceed with a statistical analysis. The histogram shown in Figure 10.1 provides an example from the fig fruits data set from the practical in Chapter 8. Figure 10.1: Example histogram fig fruit width (cm) using data from 78 fig fruits collected in in 2010 from Baja, Mexico. The histogram in Figure 10.1 shows how many fruits there are for different intervals of width (for a step-by-step demonstration of how a histogram is built, see this interactive application2). That is, the frequency with which fruits within some width interval occur in the data. For example, there are 6 fruits with a width between 1.0 and 1.2, so for this interval on the x-axis, the bar is 6 units in height on the y-axis. In contrast, there is only 1 fig fruit that has a width greater than 2.0 cm (the biggest is 2.1 cm), so we see that the height of the bar for the interval between 2.0 and 2.2 is only 1 unit in frequency. The bars of the histogram touch each other, which reinforces that the data are continuous (Dytham 2011; Sokal and Rohlf 1995). It is especially important to be able to read and understand information from a histogram because it is often necessary to determine if the data are consistent with the assumptions of a statistical test. For example, the shape of the distribution of fig fruit widths might be important for performing a particular test. For the purposes of this module, the shape of the distribution just means what the data look like when plotted like this in a histogram. In this case, there is a peak toward the centre of the distribution, with fewer low and high values (this kind of distribution is quite common). Different distribution shapes will be discussed more in Part IV (next week). 10.2 Barplots and pie charts While histograms are an effective way of visualising continuous data, barplots (also known as ‘bar charts’ or ‘bar graphs’) and pie charts can be used to visualise categorical data. For example, in the fig fruits data set Chapter 8, 78 fig fruits were collected from 4 different trees (A, B, C, and D). A barplot could be used to show how many samples were collected from each tree (see Figure 10.2). Figure 10.2: Example bar plot showing how many fruits were collected from each of 4 trees (78 collected in total) in 2010 from Baja, Mexico. In Figure 10.2, each tree is represented by a separate bar on the x-axis. Unlike a histogram, the bars do not touch each other, which reinforces that different categories of data are being shown (in this case, different trees). The height of bar indicates how many fruits were sampled for each tree. For example, 14 fruits were sampled from tree A, and 22 fruits were sampled from tree B. At a glance, it is therefore possible to compare different trees and make inferences about how they differ in sampled fruits. Pie charts are similar to barplots in that both present categorical data, but pie charts are more effective for visualising the relative quantity for each category. That is, pie charts illustrate the percentage of measurements for each category. For example, in the case of the fig fruits, it might be useful to visualise what percentage of fruits were sampled from each tree. A pie chart could be used to evaluate this, with pie slices corresponding to different trees and the size of each slice reflecting the percentage of the total sampled fruits that came from each tree (Figure 10.3). Figure 10.3: Example pie plot showing the percentage of fruits that were collected from each of 4 trees (78 collected in total) in 2010 from Baja, Mexico. Pie charts can be useful in some situations, but in the biological and environmental they are not used as often as barplots. In contrast to pie charts, barplots present the absolute quantities (in Figure 10.2, e.g., the actual number of fruits sampled per tree), and it is still possible with barplots to infer the percentage each category contributes to the total from the relative sizes of the bars. Pie charts, in contrast, only illustrate relative percentages unless numbers are used to indicate absolute quantities. Unless only percentage is important, barplots are often the preferred way to communicate count data. 10.3 Box-whisker plots Box-whisker plots (also called boxplots) can be used to visualise distributions in a different way than histograms. Instead of presenting the full distribution, as in a histogram, a box-whisker plot shows where summary statistics are located (summary statistics are explained below). This allows the distribution of data to be represented in a more compact way, but does not show the full shape of a distribution. Figure 10.4 compares a box-whisker plot of fig fruit widths (10.4A) with a histogram of fig fruit widths (10.4B). In other words, both of the panels (A and B) in Figure 10.4 show the same information in two different ways (note that these are the same data as presented in Figure 10.1). Figure 10.4: Boxplot (A) of fig fruit widths (cm) for 78 fig fruits collected in 2010 in Baja, Mexico. Panel (B) presents the same data as a histogram. To show how the panels of Figure 10.4 correspond to one another more clearly, Figure 10.5 shows them again, but with points indicating where the summary statistics shown in the boxplot (Figure 10.5A) are located in the histogram (Figure 10.5B). These summary statistics include the median (black circles of Figure 10.5), quartiles (red squares of Figure 10.5), and the limits of the distribution (i.e., the minimum and maximum values; blue triangles of Figure 10.5). Note that in boxplots, if outliers exist, they are presented as separate points. Figure 10.5: Boxplot (A) of fig fruit widths (cm) for 78 fig fruits collected in 2010 in Baja, Mexico. Panel (B) presents the same data as a histogram. Points in the boxplot indicate the median (black circle), first and third quartiles (red squares), and the limits of the distribution (blue triangles). Corresponding locations are shown on the histogram in panel (B). One benefit of a boxplot is that it is possible to show the distribution of multiple variables simultaneously. For example, the distribution of fig fruit width can be shown for each of the four trees side by side on the same x-axis of a boxplot (Figure 10.6). While it is possible to show histograms side by side, it will quickly take up a lot of space. Figure 10.6: Boxplot of fig fruit widths (cm) collected from 4 separate trees sampled in 2010 from Baja, Mexico. The boxplot in Figure 10.6 can be used to quickly compare the distribution of Trees A-D. The point at the bottom of the distribution of Tree A shows an outlier. This outlier is an especially low value of fig fruit width compared to the other fruits of Tree A. References "],["Chapter_11.html", "Chapter 11 Measures of central tendency 11.1 The mean 11.2 The mode 11.3 The median and quantiles", " Chapter 11 Measures of central tendency Summary statistics describe properties of data in a single number (e.g., the mean), or a set of numbers (e.g., quartiles). This chapter focuses on summary statistics that describe the centre of a distribution. It also introduces quantiles, which divide a distribution into different percentages of the data (e.g., the lowest 50% or highest 75%). Throughout this section, verbal and mathematical explanations of summary statistics will be presented alongside histograms or boxplots that convey the same information. The point of doing this is to help connect the two ways of summarising the data. All of the summary statistics that follow describe calculations for a sample and are therefore estimates of the true values in a population. Recall from Chapter 4 the difference between a population and a sample. This module focuses on statistical techniques, not statistical theory, so summary statistics will just focus on how to estimate statistics from sampled data instead of how statistics are defined mathematically3. 11.1 The mean The arithmetic mean (hereafter just the mean4) of a sample is one of the most commonly reported statistics when communicating information about a dataset. The mean is a measure of central tendency, so it is located somewhere in the centre of a distribution. Figure 10.7 shows the same histogram of fig fruit widths shown in Figure 10.1, but with an arrow indicating where the mean of the distribution is located Figure 11.1: Example histogram fig fruit width (cm) using data from 78 fig fruits collected in in 2010 from Baja, Mexico. The mean is calculated by adding up the values of all of the data and dividing this sum by the total number of data (Sokal and Rohlf 1995). This is a fairly straightforward calculation, so we can use the mean as an example to demonstrate some new mathematical notation that will be used throughout the module. We will start with a concrete example with actual numbers, then end with a more abstract equation describing how any sample mean is calculated. The notation might be a bit confusing at first, but learning it will make understanding statistical concepts easier later in the module. There are a lot of equations in what follows, but this is because we want to explain what is happening as clearly as possible, step by step. We start with the following 8 values. 4.2, 5.0, 3.1, 4.2, 3.8, 4.6, 4.0, 3.5 To calculate the mean of a sample, we just need to add up all of the values and divide by 8 (the total number of values), \\[\\bar{x} = \\frac{4.2 + 5.0 + 3.1 + 4.2 + 3.8 + 4.6 + 4.0 + 3.5}{8}.\\] Note that I have used the symbol \\(\\bar{x}\\) to represent the mean of \\(x\\), which is a common notation (Sokal and Rohlf 1995). In the example above, \\(\\bar{x} = 4.05\\). Writing the calculation above is not a problem because we only have 8 points of data. But sample sizes are often much larger than 8. If we had a sample size of 80 or 800, then there is no way that we could write down every number to show how the mean is calculated. One way to get around this is to use ellipses and just show the first and last couple of numbers, \\[\\bar{x} = \\frac{4.2 + 5.0 + ... + 4.0 + 3.5}{8}.\\] This is a more compact, and perfectly acceptable, way to write the sample mean. But it is often necessary to have an even more compact way of indicating the sum over a set of values (i.e., the top of the fraction above). To do this, each value can be symbolised by an \\(x\\), with a unique subscript \\(i\\), so that \\(x_{i}\\) corresponds to a specific value in the list above. The usefulness of this notation, \\(x_{i}\\), will become clear soon. It takes some getting used to, but the table below shows each symbol with its corresponding value to make it more intuitive. A sample dataset that includes eight values. Symbol Value \\(x_{1}\\) 4.2 \\(x_{2}\\) 5.0 \\(x_{3}\\) 3.1 \\(x_{4}\\) 4.2 \\(x_{5}\\) 3.8 \\(x_{6}\\) 4.6 \\(x_{7}\\) 4.0 \\(x_{8}\\) 3.5 Note that we can first replace the actual values with their corresponding \\(x_{i}\\), so the mean can be written as, \\[\\bar{x} = \\frac{x_{1} + x_{2} + x_{3} + x_{4} + x_{5} + x_{6} + x_{7} + x_{8}}{8}.\\] Next, we can rewrite the top of the equation in a different form using a summation sign, \\[\\sum_{i = 1}^{8}x_{i} = x_{1} + x_{2} + x_{3} + x_{4} + x_{5} + x_{6} + x_{7} + x_{8}.\\] Like the use of \\(x_{i}\\), the summation sign \\(\\sum\\) takes some getting used to, but here it just means “sum up all of the \\(x_{i}\\) values”. You can think of it as a big ‘S’ that just says “sum up”. The bottom of the S is the starting point and the top of it is the ending point for adding numbers. Verbally, we can read this as saying, “starting with \\(i = 1\\), add up all of the \\(x_{i}\\) values until \\(i = 8\\)”. We can then replace the long list of \\(x\\) values with a summation, \\[\\bar{x} = \\frac{\\sum_{i = 1}^{8}x_{i}}{8}.\\] This looks a bit messy, so we can rewrite the above equation. Instead of dividing the summation by 8, we can multiply it by 1/8, which gives us the same answer, \\[\\bar{x} = \\frac{1}{8}\\sum_{i = 1}^{8}x_{i}.\\] There is one more step. We have started with 8 actual values and ended with a compact and abstract equation for calculating the mean. But if we want a general description for calculating any mean, then we need to account for sample sizes not equal to 8. To do this, we can use \\(N\\) to represent the sample size. In our example, \\(N = 8\\), but it is possible to have a sample size be any finite value above zero. We can therefore replace 8 with \\(N\\) in the equation for the sample mean, \\[\\bar{x} = \\frac{1}{N}\\sum_{i = 1}^{N}x_{i}.\\] There we have it. Verbally, the above equation tells us to multiply \\(1/N\\) by the sum of all \\(x_{i}\\) values from 1 to \\(N\\). This describes the mean for any sample that we might collect. 11.2 The mode The mode of a dataset is simply the value that appears most often. As a simple example, we can again consider the sample dataset of 8 values. 4.2, 5.0, 3.1, 4.2, 3.8, 4.6, 4.0, 3.5 In this dataset, the values 5.0, 3.1, 3.8, 4.6, 4.0, and 3.5 are all represented once. But the value 4.2 appears twice, once in the first position and once in the fourth position. Because 4.2 therefore appears most frequently in the dataset, it is the mode of the dataset. Note that it is possible for a dataset to have more than one mode. Also, somewhat confusingly, distributions that have more than one peak are often described as multimodal, even if the peaks are not of the same height (Sokal and Rohlf 1995). For example, the histogram in Figure 11.2 might be described as bimodal because it has two distinct peaks (one around 10 and the other around 14), even though these peaks are not the same size. Figure 11.2: Example histogram of a hypothetical dataset that has a bimodal distribution. In very rare cases, data might have a U-shape. The lowest point of the U would then be described as the antimode (Sokal and Rohlf 1995). 11.3 The median and quantiles The median of a dataset is the middle value when the data are sorted. More technically, the median is defined as the value that has the same number of lower and higher values than it (Sokal and Rohlf 1995). If there are an odd number of values in the dataset, then finding the median is often easy. For example, the median of the values {8, 5, 3, 2, 6} is 5. This is because if we sort the values from lowest to highest (2, 3, 5, 6, 8), the value 5 is exactly in the middle. It gets more complicated for an even number of values, such as the sample dataset used for explaining the mean and mode. 4.2, 5.0, 3.1, 4.2, 3.8, 4.6, 4.0, 3.5 We can order these values from lowest to highest. 3.1, 3.5, 3.8, 4.0, 4.2, 4.2, 4.6, 5.0 Again, there is no middle value here. But we can find a value that has the same number of lower and higher values. To do this, we just need to find the mean of the middle 2 numbers, in this case 4.0 and 4.2, which are in positions 4 and 5, respectively. The mean of 4.0 and 4.2 is, \\((4.0 + 4.2)/2 = 4.1\\), so 4.1 is the median value. The median is a type of quantile. A quantile divides a sorted dataset into different percentages that are lower or higher than it. Hence, the median could also be called the 50% quantile because 50% of values are lower than the median and 50% of values are higher than it. Two other quantiles besides the median are also noteworthy. The first quartile (also called the “lower quartile”) defines the value for which 25% of values of lower and 75% of values are higher. The third quartile (also called the “upper quartile”) defines the value for which 75% of values are lower and 25% of values are higher. Sometimes this is easy to calculate. For example, if there are only five values in a dataset, then the lower quartile is the number in the second position when the data are sorted because 1 value (25%) is below it and 3 values (75%) are above it. For example, for the values {1, 3, 4, 8, 9}, the value 3 is the first quartile and 8 is the third quartile. In some cases, it is not always this clear. We can show how quantiles get more complicated using the same 8 values as above where the first quartiles is somewhere between 3.5 and 3.8. 3.1, 3.5, 3.8, 4.0, 4.2, 4.2, 4.6, 5.0 There are at least 9 different ways to calculate the first quartile in this case, and different statistical software package will sometimes use different default methods (Hyndman and Fan 1996). One logical way is to calculate the mean between the second (3.5) and third (3.8) position as you would do for the median (Rowntree 2018), \\((3.5 + 3.8) / 2 = 3.65\\). Jamovi uses a slightly more complex method, which will give a value of \\(3.725\\). It is important to emphasise that no one way of calculating quantiles is the one and only correct way. Statisticians have just proposed different approaches to calculating quantiles from data, and these different approaches sometimes give slightly different results. This can be unsatisfying when first learning statistics because it would be nice to have a single approach that is demonstrably correct, i.e., the right answer under all circumstances. Unfortunately, this is not the case here, nor is it the case for a lot of statistical techniques. Often there are different approaches to answering the same statistical question and no simple right answer. For this module, we will almost always be reporting calculations of quantiles from Jamovi, and we will clearly indicate that this is how they should be calculated for assessment questions. But it is important to recognise that different statistical tools might give different answers (Hyndman and Fan 1996). References "],["Chapter_12.html", "Chapter 12 Measures of spread 12.1 The range 12.2 The inter-quartile range 12.3 The variance 12.4 The standard deviation 12.5 The coefficient of variation 12.6 The standard error", " Chapter 12 Measures of spread 12.1 The range 12.2 The inter-quartile range 12.3 The variance 12.4 The standard deviation 12.5 The coefficient of variation 12.6 The standard error "],["Chapter_13.html", "Chapter 13 Practical. Plotting and statistical summaries in Jamovi 13.1 Reorganise the dataset into a tidy format 13.2 Histograms and box-whisker plots 13.3 Calculate summary statistics 13.4 Reporting decimals and significant figures 13.5 Comparing across sites", " Chapter 13 Practical. Plotting and statistical summaries in Jamovi This practical focuses on applying the concepts from Chapters 9-12 in Jamovi. The data that we will work with in this practical were collected from a research project conducted by Dr Alan Law, Prof Nils Bunnefeld, and Prof Nigel Willby at the University of Stirling (Law, Bunnefeld, and Willby 2014). The project focused on beaver reintroduction in Scottish habitats and its consequences for the white water lily, Nymphaea alba, which beavers regularly consume (Figure 13.1)5. Figure 13.1: Photo of white water lillies on the water. As an instructive example, this lab will use the data from Law, Bunnefeld, and Willby (2014) on the petiole diameter (mm) from N. alba collected from 7 different sites on the west coast of Scotland (the petiole is the structure that attaches the plant stem to the blade of the leaf). The N. alba dataset is available to download here. Note that the data are not in a tidy format, so it is important to first reorganise the data so that they can be analysed in Jamovi (13.1). Once the data are properly organised, we will use Jamovi to plot them (13.2), calculate summary statistics (13.3), apply appropriate decimals, significant figures, and rounding (13.4), and compare petiole diameters across sites (13.5). 13.1 Reorganise the dataset into a tidy format The N. alba dataset is not in a tidy format. All of the numbers from this dataset are measurements of petiole diameter in mm from N. alba, but each row contains 7 samples because each column shows a different site. The full dataset is shown below. ## Lily_Loch Choille.Bharr Creig.Moire Fidhle Buic Linne Beag ## 1 7.42 2.39 2.39 2.97 2.84 3.73 6.12 ## 2 3.58 4.22 4.65 6.68 4.19 5.21 3.23 ## 3 7.47 2.41 5.16 3.78 6.50 3.78 7.04 ## 4 6.07 5.54 2.87 7.11 3.20 3.71 3.05 ## 5 6.81 3.56 6.63 2.74 4.14 6.93 7.06 ## 6 8.05 5.72 7.42 4.75 2.51 6.40 9.58 ## 7 7.24 4.72 3.66 5.59 8.53 1.57 4.62 ## 8 7.90 5.05 7.26 3.94 6.25 3.20 8.66 ## 9 6.15 6.76 3.71 5.44 6.17 4.55 3.96 ## 10 6.20 5.64 3.20 4.98 3.53 2.62 5.26 ## 11 7.26 4.06 5.99 4.24 5.03 3.48 3.53 ## 12 7.06 9.25 6.38 5.51 6.10 2.67 8.33 ## 13 6.45 5.99 5.49 6.48 4.98 9.40 5.41 ## 14 3.66 4.57 4.93 5.69 5.21 6.86 7.32 ## 15 4.37 6.96 7.29 2.79 5.03 6.20 5.46 ## 16 4.55 6.78 6.10 5.72 7.19 4.93 4.34 ## 17 3.81 7.29 5.97 4.39 6.32 5.18 6.35 ## 18 2.77 5.16 9.93 7.19 7.04 6.12 6.12 ## 19 1.91 8.64 8.28 7.29 6.35 7.26 5.11 ## 20 2.62 7.01 7.24 8.18 6.30 9.14 8.18 Remember that to make these data tidy and usable in Jamovi, we need each row to be an independent sample. What we really want then is a dataset with two columns of data. The first column should indicate the site, and the second column should indicate the petiole diameter. This can be done in two ways. First, we could use a spreadsheet programme like LibreOffice or MS Excel to create a new dataset with two columns, one column with the site information and the other column with the petiole diameters. Second, we could use the ‘Data’ tab in Jamovi to create two new columns of data (one for site and the other for petiole diameter). Either way, we need to copy and paste site names into the first column and petiole diameters in the second column. This is a bit tedious, and we will not ask you to do it for every dataset, but it is an important step in the process of data analysis. See Figure 13.2 for how this would look in Jamovi. Figure 13.2: Tidying the raw data of petiole diameters from lily pad measurements across 7 sites in Scotland. A new column of data is created by right clicking on an existing column and choosing ‘Add Variable’. Note that to insert a new column, we need to right click on an existing column and select ‘Add Variable’ \\(\\to\\) ‘Insert’. A new column will then pop up in Jamovi, and we can give this an informative name. Make sure to specify that the ‘Site’ column should be a nominal measure type, and the ‘petiole_diameter_mm’ column should be a continuous measure type. The first 6 rows of the dataset should look like the below. ## Site petiole_diameter_mm ## 1 Lily_Loch 7.42 ## 2 Lily_Loch 3.58 ## 3 Lily_Loch 7.47 ## 4 Lily_Loch 6.07 ## 5 Lily_Loch 6.81 ## 6 Lily_Loch 8.05 With the reorganised dataset, we are now ready to do some analysis in Jamovi. We will start with some plotting. 13.2 Histograms and box-whisker plots We will start by making a histogram of the full dataset of petiole diameter. To do this, we need to go to ‘Analyses’ tab of the Jamovi toolbar, then select the ‘Exploration’ button. Figure 13.3: Jamovi toolbar after having selected on the Analyses tab followed by the Exploration button. Next, select the ‘Descriptives’ option (Figure 13.3). This will open a new window where it is possible to create plots and calculate summary statistics. The white box on the left of the Descriptive interface lists all of the variables in the dataset. Below this box, there are options for selecting different summary statistics ‘Statistics’ and building different graphs ‘Plots’. To get started, select the petiole diameter variable in the box to the left, then move it to the ‘Variables’ box (top right) using the \\(\\to\\) arrow. Next, open the Plots option at the bottom of the interface. Choose the ‘Histogram’ option by clicking the checkbox. A histogram will open up in the window on the right (you might need to scroll down). Figure 13.4: Jamovi Descriptives toolbar with petiole diameter selected and a histogram produced in the plotting window. Take a look at the histogram to the right (Figure 13.4). Just looking at the histogram, write down what you think the following summary statistics will be. Mean: ____________________________ Median: ____________________________ Standard deviation: ____________________________ Based on the histogram, do you think that the mean and median are the same? Why or why not? The histogram needs better labelled axes and an informative caption. To label the axes better, go back to the data tab and double click on the column heading ‘petiole_diameter_mm’. Change the name of the data variable to ‘Petiole diameter (mm)’. The newly named variable will then appear when a new histogram of the petiole diameter data is made. To write a caption in Jamovi, click on the ‘Edit’ tab at the very top of the toolbar. You will see some blue boxes above and below the histogram, and you can write your caption by clicking on the box immediately below the histogram. Write a caption for the histogram below. If you want to save the histogram, then you can right click on it. A pop-up box will give you several options; select ‘Image \\(\\to\\) Export’ to save the histogram. You can save it as a PDF, PNG, SVG, or EPS (if in doubt, PNG is probably the easiest to use). You do not need to do this for this lab, but knowing how to do it will be useful for other modules, including your fourth year dissertation. In the first example, we looked at petiole diameters across the entire dataset, but suppose that we want to see how the data are distributed for each site individually. To do this, we just need to go back to the Descriptives box (Figure 13.4) and put the ‘Site’ variable into the box on the lower right called ‘Split by’. Do this by selecting ‘Site’ then using the lower \\(\\to\\) arrow to bring it to the ‘Split by’ box. Instead of one histogram of petiole diameters, you will now see 7 different histograms, one for each site, all stacked on top of each other. This might be useful, but all of these histograms together are a bit busy. Instead, we can use a box-whisker plot to compare the distributions of petiole diameters across different sites. To create a box plot, simply check ‘Box plot’ from the Plots options (you might want to uncheck ‘Histogram’, but it is not necessary). You should now see all of the different sites on the x-axis of the newly created boxplot and a summary of the petiole diameters on the y-axis. Based on the boxplot, which site appears to have the highest and lowest median petiole diameter? Highest: ____________________________ Lowest: ____________________________ There is one more trick with box-whisker plots in Jamovi that is useful. The current plots show a summary of each site, but it might also be useful to plot the actual data points to give some more information about the distribution of petiole diameters. You can do this by checking the option ‘Data’, which places the petiole diameter of each sample over the box and whiskers for each site. The y-axis shows the petiole diameter of each data point. By default, the points are jittered on the x-axis, which just means that they are placed randomly on the x-axis within a site. This is just to ensure that points will not be placed directly on top of each other if they are the same value. If you prefer, you can use the pull-down menu right below the Data checkbox to select ‘Stacked’ instead of ‘Jittered’ The stacked option will place points side by side. Think about where the points are in relation to the box and whiskers of the plot; this should help you develop an intuitive understanding of how to read box-whisker plots. 13.3 Calculate summary statistics We can calculate the summary statistics using the ‘Descriptives’ option in Jamovi, just as we did with the histogram and box-whisker plots. Before doing anything else, again place the petiole diameter variable in the box of variables, but do not split the dataset by site just yet because we first want summary statistics across the entire dataset. Below the box of variables, but above the Plots options, there are options for selecting different summary statistics. Open up this new box and have a look at the different summary statistics that can be calculated. To calculate all of the variables explained in Chapter 11 and Chapter 12, check the following 11 boxes: N: _______________________ Std. deviation: _______________________ Variance: _______________________ Range: _______________________ Minimum: _______________________ Maximum: _______________________ Range: _______________________ IQR: _______________________ Mean: _______________________ Median: _______________________ Mode: _______________________ Std. error of mean: _______________________ When you do this, the Statistics option in Jamovi should like like it does in Figure 13.5. Figure 13.5: Jamovi Descriptives toolbar showing the summary statistics available to report. Once you check these boxes, you will see a ‘Descriptives’ table open on the right hand side of Jamovi. This table will report all of the summary statistics that you have checked. Write down the values for the summary statistics next to the corresponding bullet points above. Next split these summary statistics up by site. Notice the very large table that is now produced on the right hand side of Jamovi. Which of the 7 sites in the data set has the highest mean petiole diameter, and what is its mean? Site: ______________________________ Mean: ______________________________ Which of the 7 sites has the lowest variation in petiole diameter, and what is its variation? Site: ______________________________ Variation: ______________________________ Make sure that you are able to find and interpret these summary statistics in Jamovi. Explore different options to get more comfortable using Jamovi for building plots and reporting summary statistics. Can you find the first and third quartiles for each site? Report the third quartiles for each site below. Beag: ______________________________ Buic: ______________________________ Choille-Bharr: ______________________________ Creig-Moire: ______________________________ Fidhle: ______________________________ Lily_Loch: ______________________________ Linne: ______________________________ Next, we will look at reporting summary statistics to different significant figures. 13.4 Reporting decimals and significant figures Using the same values that you reported above for the whole dataset (i.e., not broken down by site), report each summary statistics to two significant figures. Remember to round accurately if you need to reduce the number of significant figures from the original values to the new values below. In assessments, you will often be asked to report a particular answer to a specific number of decimal places or significant figures, so the intention here is to help you practice. N: _______________________ Std. deviation: _______________________ Variance: _______________________ Range: _______________________ Minimum: _______________________ Maximum: _______________________ Range: _______________________ IQR: _______________________ Mean: _______________________ Median: _______________________ Mode: _______________________ Std. error of mean: _______________________ Remember from 13.2 that you were asked to write down what you thought the mean, median, and standard deviation were just by inspecting the histogram. Compare your answers in that section with the rounded statistics listed above. Were you able to get a similar value from the histogram as calculated in Jamovi from the data? What can you learn from the histogram that you cannot from the summary statistics, and what can you learn from the summary statistics that you cannot from the histogram? Write your reflections in the space below. Next, we will produce barplots to show the mean petiol diameter for each site. 13.5 Comparing across sites To make a barplot that compares the mean petiole diameters across sites, we again use the Descriptives option in Jamovi. Place petiole diameter as the variable, and spit this by site. Next, go down to the plotting options and check ‘Bar plot’. You will see a barplot produced in the window to the right with different sites on the x-axis. Bar heights show the mean petiole diameter for each site. Notice the intervals shown for each bar (i.e., the vertical lines in the centre of the bars that go up and down different lengths). These error bars are centred on the mean petiole diameter (bar height) and show one standard error above and below the site mean. Recall back from Chapter 12; what information do these error bars convey about the estimated mean petiole diameter? What can you say about the mean petiole diameters across the different sites? Do these sites appear to have very different mean petiole diameters? There were 20 total petiole diameters sampled from each site. If we were to go back out to these 7 sites and sample another 20 petiole diameters, could we really expect to get the exact same site means? Assuming the site means would be at least a bit different for our new sample, is it possible that the sites with the highest or lowest petiole diameters might also be different in our new sample? If so, then what does this say about our ability to make conclusions about the differences in petiole diameter among sites? References "],["week-4-overview.html", "Week 4 Overview", " Week 4 Overview General overview of what will be the focus of this week. Week: 4 Dates: Suggested Readings: Textbook intro to probability Assessments: Practice quiz Practical: "],["introduction-to-probability-models.html", "Chapter 14 Introduction to probability models 14.1 A practical example 14.2 Probability distributions", " Chapter 14 Introduction to probability models Some background 14.1 A practical example How to think about probability 14.2 Probability distributions Some more useful examples 14.2.1 Binomial distribution Explanation, fairly straightforward 14.2.2 Poisson distribution Another example 14.2.3 Normal distribution Why this is so important "],["the-central-limit-theorem-clt.html", "Chapter 15 The Central Limit Theorem (CLT) 15.1 Examples of the CLT in action 15.2 The standard normal distribution 15.3 What are z-scores?", " Chapter 15 The Central Limit Theorem (CLT) General overview 15.1 Examples of the CLT in action 15.2 The standard normal distribution 15.3 What are z-scores? "],["practical.-probability-and-simulation.html", "Chapter 16 Practical. Probability and simulation 16.1 Probabilities from a dataset 16.2 Probabilities from a normal distribution 16.3 Central limit theorem 16.4 Calculating probability exercise 1 16.5 Calculating probability exercise 2 16.6 Calculating probability from normal distribution 16.7 Normal distribution and sample size 16.8 Simulating the central limit theorem", " Chapter 16 Practical. Probability and simulation This practical focuses on applying the concepts from chapter 14 and 15 in Jamovi. There will be 3 exercises. Calculating probabilities from a dataset. Calculating probabilities from a normal distribution. Demonstrating the central limit theorem (CLT). To complete exercises 2 and 3, we will need to download and install two new Jamovi modules. Jamovi Modules are add-ons that make it possible to run specialised statistical tools inside Jamovi. These tools are written by a community of statisticians, scientists, and educators and listed in the Jamovi library. Like Jamovi, these tools are open source and free to use. The dataset for this practical is something a bit different. It comes from the Beacon Project, which is an interdisciplinary scientific research programme led by Dr Isabel Jones at the University of Stirling. This project focuses on large hydropower dams as a way to understand the trade-offs between different United Nations Sustainable Development Goals. It addresses challenging questions about environmental justice, biodiversity, and sustainable development. The project works with people affected, and sometimes displaced, by dam construction in Brazil, Kazakhstan, India, USA, and the UK. Part of this project involves the use of mobile games to investigate how people make decisions about sustainable development. Figure 16.1: Welcome screen of the mobile game Power Up! The game “Power Up!” is freely available as an Android and iPhone app (Figure 16.1). Data are collected from players’ decisions and used to investigate social-ecological questions. We will use the power_up dataset in exercises 1 and 2. To get started, first download the power_up dataset and open them in Jamovi. Note that these data are already in a tidy format, so we do not need to do any reorganising. The dataset includes columns for each player’s ID, the OS that they use, the dam size that they decided to build in the game, their in-game investment in Biodiversity, Community, and Energy, and their final Score. 16.1 Probabilities from a dataset Suppose that we want to estimate the probability that a new Power Up! game player will be an Android user. To estimate this probability, we can use the proportion of players in the dataset who are Android users. To get this proportion, we need to divide the number of Android users by the total number of players, \\[P_{(Android)} = \\frac{Number\\:of\\:Android\\:users}{Number\\:of\\:players}.\\] In Jamovi, you could figure this out the long way by counting up the number of rows with ‘Android’ in the second column, then dividing by the total number of rows. But there is an easier way, which is faster and less prone to human error than manually tallying up items. To do this, go to the Analyses tab in Jamovi and navigate to Exploration, then Descriptives. Place the ‘OS’ variable in to the ‘Variables’ box. Next, find the check box called ‘Frequency tables’ just under the ‘Split by’ box and above the ‘Statistics’ drop down tab. Check this box to get a table of frequencies for Android versus iPhone users. Figure 16.2: Jamovi Descriptives toolbar showing the OS column from the Power Up! dataset selected. The ‘Frequency tables’ checkbox builds a table of counts and percentages. The table of frequencies shown in Figure 16.2 includes counts of Android versus iPhone users. We can see that 56 of the 74 total game players use Android, while 18 players use iPhone. To get the proportion of Android users we could divide 56 by 74 to get 0.7567568. Similarly, the proportion of iPhone users, we could calculate 18 / 74 = 0.2432432. But Jamovi already does that for us, with a bit of rounding. The second column of the Frequencies table gives us these proportions, but expressed as a percentage. The percentage of Android users is 75.7%, and the percentage of iPhone users is 24.3%. Percentages are out of a total of 100, so to get back to the proportions, we can just divide by 100, 75.7 / 100 = 0.757 for Android and 24.3 / 100 = 0.243 for iPhone. To answer the original question, our best estimate of the probability that a new Power Up! game player will be an Android user is therefore 0.757. Next, use the same procedure to find the probability that a game player will make a small, medium, and large size dam. Now, fill in Table 16.1 with counts, percentage, and the estimated probability of a player selecting a small, medium, or large dam. Statistics of Power Up! decisions for dam size. Dam size Counts Percentage Estimated Probability Small Medium Large We can use these estimated probabilities of small, medium, and large dam size selection to predict what will happen in future games. Suppose that a new player decides to play the game. What is the probability that this player chooses a small or a large dam? \\(Pr_{(small\\:or\\:large)} =\\) : __________________________ Now suppose that 3 new players arrive and decide to play the game. What is the probability that all 3 of these new players choose a large dam? \\(Pr_{(3\\:large)} =\\) : __________________________ What is the probability that all 3 of these new players choose different dam sizes? \\(Pr_{(small,\\:medium,\\:large)} =\\) : __________________________ Now consider a slightly different type of question. Instead of trying to predict the probability of new player decisions, we will focus on sampling from the existing power up dataset. Imagine that you randomly choose one of the 74 players with equal probability (i.e., every player is equally likely to be chosen). What is the probability that you choose player 20? \\(Pr_{(Player\\:20)} =\\) : __________________________ What is the probability that you choose player 20, then choose a different player with a large dam? As a hint, remember that you are now sampling without replacement. The second choice cannot be player 20 again, so the probability of choosing a player with a large dam has changed from the estimated probability in Table 16.1. \\(Pr_{(Player\\:20,\\:Large)} =\\) : __________________________ Now we can use the Descriptives tool in Jamovi to ask a slightly different question with the data. Suppose that we wanted to estimate the probability that an Android user will choose a large dam. We could multiply the proportion of Android users times the proportion of players who choose a large dam (i.e., find the probability of Android and large dam). But this assumes that the two characteristics are independent (i.e., that Android users are not more or less likely than iPhone users to build large dams). To estimate the probability that a player chooses a large dam given that they are using Android, we can keep Dam_size in the Variables box, but now put OS in the ‘Split by’ box. Figure 16.3 shows the output of Jamovi. A new frequency table breaks down dam choice for each OS. Figure 16.3: Jamovi Descriptives toolbar showing the dam size column from the Power Up! dataset selected as a variable split by OS. The ‘Frequency tables’ checkbox builds a table of counts for small, medium, and large dam size broken down by Android versus iPhone OS. To get the proportion of Android users who choose to build a large dam, we just need to divide the number of Android users who chose the large dam size by the total number of Android users (i.e., sum of the first column in the Frequencies table; Figure 16.3). \\[P_{(Large | Android)} = \\frac{Number\\:of\\:Android\\:users\\:choosing\\:large\\:dam}{Number\\:of\\:Android\\:users}.\\] Now, recreate the table in Figure 16.3 and estimate the probability that an Android user will choose to build a large dam, \\(P_{(Large | Android)} =\\) : __________________________ Is \\(P_{(Large | Android)}\\) much different from the probability that any player chooses a large dam, as calculated in Table 16.1? Do you think that the difference is significant? Next, we will move on to calculating probabilities from a normal distribution. 16.2 Probabilities from a normal distribution In the example of the first exercise, we looked at OS and dam size choice. Players only use Android or iPhone, and they could only choose one of three sizes of dam. For these nominal variables, estimating the probability of a particular discrete outcome (e.g., Android versus iPhone) was just a matter of dividing counts. But we cannot use the same approach for calculating probabilities from continuous data. Consider, for example, the final score for each player in the column ‘Score’. Because of how the game was designed, Score can potentially be any real number, although most scores are somewhere around 100. We can use a histogram to see the distribution of player scores (Figure 16.4). Figure 16.4: Distribution of player scores in the game Power Up! In this case, it does not really make sense to ask what the probability is of a particular score. If the score can take any real value, out to as many decimals as we want, then what is the probability of a score being exactly 94.97 (i.e., 94.97 with infinite zeros after it, \\(94.9700000\\bar{0}\\))? The probability is infinitesimal, i.e., basically zero, because there are an infinite number of real numbers. Consequently, we are not really interested in the probabilities of specific values of continuous data. Instead, we want to focus on intervals. For example, what is the probability that a player scores higher than 120? What is the probability that a player scores lower than 100? What is the probability that a player scores between 120 and 100? Take another look at Figure 16.4 above, then take a guess at each of these probabilities. As a hint, the y-axis of this histogram is showing density instead of frequency. What this means is that the total grey area (i.e., the histogram bars) sums to 1. Guessing the probability that a player scores higher than 120 is the same as guessing the proportion of grey space in the highest 4 bars of Figure 16.4 (i.e., grey space &gt;120). \\(P_{(Score&gt;120)} =\\) : __________________________ \\(P_{(Score&lt;100)} =\\) : __________________________ \\(P_{(100&lt;Score&lt;120)} =\\) : __________________________ Trying to do this by looking at a histogram is not easy, and it is really not the best way to get the above probabilities. We can get much better estimates using Jamovi, but we need to make an assumption about the distribution of Player Score. Specifically, we need to assume that the distribution of Player Score has a specific shape. More technically, we must assume a specific probability density function that we can use to mathematically calculate probabilities of different ranges of player scores. Inspecting Figure 16.4, Player Score appears to be normally distributed. In other words, the shape of Player Score distribution appears to be normal, or ‘Gaussian’. If we are willing to assume this, then we can calculate probabilities using its mean and standard deviation. Use Jamovi to find the mean and the standard deviation of player score (note, we can just say that score is unitless, so no need to include units). Mean score: __________________________ Standard deviation score: __________________________ We will assume that the sample of scores shown in Figure 16.4 came from a population that is normally distributed with the mean and standard deviation above that you wrote above (recall sample versus population from Chapter 4). We can overlay his distribution on the histogram above using a curved line (Figure 16.5). Figure 16.5: Distribution of player scores in the game Power Up! shown in histogram bars. The overlaid curve shows the probability density function for a normal distribution that has the same mean and standard deviation as the sample described by the histogram. We can interpret the area under the curve in the same way that we interpret the area in the grey bars. As mentioned earlier, the total area of the histogram bars must sum to 1. The total area under the curve must also sum to 1. Both represent the probability of different ranges of player scores. Notice that the normal distribution is not a perfect match for the histogram bars. For example, the middle bar of values illustrating scores between 90 and 100 appears to be a bit low compared to a perfect normal distribution, and there are more scores between 40 and 50 than we might expect. Nevertheless, the two distributions broadly overlap, so we might be willing to assume that the player scores represented in the histogram bars are sampled from the population described by the curve. Because the curve relating player score to probability density is described by an equation (see Chapter 14), we can use that equation to make inferences about the probabilities of different ranges of scores. The simplest example is the mean. Because the normal distribution is symmetric, the area to the left of the mean must be the same as the area to the right of the mean. And since the whole area under the curve must sum to 1, we can conclude that the probability of sampling a player score that is less than the mean is 1/2, and the probability of sampling a player score greater than the mean is also 1/2. Traditionally, we would need to do some maths to get other player score probabilities, but Jamovi can do this much more easily. To get Jamovi to calculate probabilities from a normal distribution, we need to go to the Modules option and download a new module (Figure 16.5). Figure 16.6: Jamovi tool bar, which includes an option for downloading new Modules (right hand side) Click on the ‘Modules’ button, and select the first option called ‘jamovi library’ from the pull-down menu. From the ‘Available’ tab, scroll down until you find the Module called ‘distrACTION - Quantiles and Probabilities of Continuous and Discrete Distributions’ (Rihs and Mayer 2018). Click the ‘Install’ button to install it into Jamovi. A new button in the toolbar called ‘distrACTION’ should become visible (Figure 16.6). Figure 16.7: Jamovi tool bar, which includes an added module called distrACTION. If the module is not there, then it should be possible to find by again going to Modules and selecting distrACTION from the pulldown menu. Click on the module and choose ‘Normal Distribution’ from the pulldown menu. 16.3 Central limit theorem 16.4 Calculating probability exercise 1 Example exercise 1 with some simple probability calculations 16.5 Calculating probability exercise 2 Example exercise 2 with some simple probability calculations 16.6 Calculating probability from normal distribution Example exercise for getting a the probability of some value sampled above, below, or between some threshold in Jamovi. 16.7 Normal distribution and sample size Showing how we get closer to the normal distribution as sample size increases in Jamovi. 16.8 Simulating the central limit theorem Doing the example from a uniform distribution in Jamovi. References "],["week-5-overview.html", "Week 5 Overview", " Week 5 Overview General overview of what will be the focus of this week. Week: 5 Dates: Suggested Readings: Textbook intro to probability Assessments: Practice quiz Practical: "],["sample-statistics-and-population-parameters.html", "Chapter 17 Sample statistics and population parameters", " Chapter 17 Sample statistics and population parameters An explanation of this "],["standard-normal-distribution.html", "Chapter 18 Standard Normal Distribution", " Chapter 18 Standard Normal Distribution What this means, and why it is important. "],["confidence-intervals.html", "Chapter 19 Confidence intervals", " Chapter 19 Confidence intervals How these are calculated, and how to interpret them "],["the-t-interval.html", "Chapter 20 The t-interval", " Chapter 20 The t-interval What this is and how it relates to the normal distribution, and why it is important. "],["practical.-z--and-t--intervals.html", "Chapter 21 Practical. z- and t- intervals 21.1 Example constructing confidence intervals 21.2 Confidence interval for different levels (t- and z-) 21.3 Proportion confidence intervals 21.4 Another confidence interval example?", " Chapter 21 Practical. z- and t- intervals 21.1 Example constructing confidence intervals 21.2 Confidence interval for different levels (t- and z-) 21.3 Proportion confidence intervals 21.4 Another confidence interval example? "],["week-6-overview-reading-week.html", "Week 6 Overview (Reading week)", " Week 6 Overview (Reading week) This is a special chapter for week 6, which is a reading week, and it will function as a very brief pause for review. It will also ensure that the numbers of chapters will correspond to weeks. "],["week-7-overview.html", "Week 7 Overview", " Week 7 Overview General overview of what will be the focus of this week. Week: 7 Dates: Suggested Readings: Textbook Assessments: Practice quiz Practical: "],["what-is-hypothesis-testing.html", "Chapter 22 What is hypothesis testing?", " Chapter 22 What is hypothesis testing? An explanation of this, and that we are starting to get into some of the more interesting bits of inferential statistics. "],["making-and-using-hypotheses-and-types-of-tests.html", "Chapter 23 Making and using hypotheses and types of tests", " Chapter 23 Making and using hypotheses and types of tests What this means, and why it is important. "],["an-example-of-hypothesis-testing.html", "Chapter 24 An example of hypothesis testing", " Chapter 24 An example of hypothesis testing Errors "],["hypothesis-testing-and-confidence-intervals.html", "Chapter 25 Hypothesis testing and confidence intervals", " Chapter 25 Hypothesis testing and confidence intervals Relationship between these two. "],["student-t-distribution-and-one-sample-t-test.html", "Chapter 26 Student t-distribution and one sample t-test", " Chapter 26 Student t-distribution and one sample t-test What this is and how to do it in Jamovi. "],["another-example-of-a-one-sample-t-test.html", "Chapter 27 Another example of a one sample t-test", " Chapter 27 Another example of a one sample t-test From the lectures "],["independent-t-test.html", "Chapter 28 Independent t-test", " Chapter 28 Independent t-test What this is and how to use it in Jamovi. "],["paired-sample-t-test.html", "Chapter 29 Paired sample t-test", " Chapter 29 Paired sample t-test Another explanation, example, and how to do it in Jamovi. "],["violations-of-assumptions.html", "Chapter 30 Violations of assumptions", " Chapter 30 Violations of assumptions What to do in this case "],["non-parametric-tests-and-what-these-are..html", "Chapter 31 Non-parametric tests, and what these are.", " Chapter 31 Non-parametric tests, and what these are. Explanation of how to do them in Jamovi. "],["practical.-hypothesis-testing-and-t-tests.html", "Chapter 32 Practical. Hypothesis testing and t-tests 32.1 Exercise on a simple one sample t-test 32.2 Exercise on an independent sample t-test 32.3 Exercise involving multiple comparisons 32.4 Exercise with non-parametric 32.5 Another exercise with non-parametric", " Chapter 32 Practical. Hypothesis testing and t-tests 32.1 Exercise on a simple one sample t-test 32.2 Exercise on an independent sample t-test 32.3 Exercise involving multiple comparisons 32.4 Exercise with non-parametric 32.5 Another exercise with non-parametric "],["week-8-overview.html", "Week 8 Overview", " Week 8 Overview General overview of what will be the focus of this week. Week: 8 Dates: Suggested Readings: Textbook Assessments: Practice quiz Practical: "],["what-is-anova.html", "Chapter 33 What is ANOVA?", " Chapter 33 What is ANOVA? General explanation "],["one-way-anova.html", "Chapter 34 One-way ANOVA", " Chapter 34 One-way ANOVA Explain what this is. "],["two-way-anova.html", "Chapter 35 Two-way ANOVA", " Chapter 35 Two-way ANOVA More explanation "],["kruskall-wallis-h-test.html", "Chapter 36 Kruskall-Wallis H test", " Chapter 36 Kruskall-Wallis H test Non-parametric explanation "],["practical.-anova-and-associated-tests.html", "Chapter 37 Practical. ANOVA and associated tests 37.1 ANOVA Exercise 1 37.2 ANOVA Exercise 2 37.3 ANOVA Exercise 3 37.4 ANOVA Exercise 4", " Chapter 37 Practical. ANOVA and associated tests 37.1 ANOVA Exercise 1 37.2 ANOVA Exercise 2 37.3 ANOVA Exercise 3 37.4 ANOVA Exercise 4 "],["week-9-overview.html", "Week 9 Overview", " Week 9 Overview General overview of what will be the focus of this week. Week: 9 Dates: Suggested Readings: Textbook Assessments: Practice quiz Practical: "],["frequency-and-count-data.html", "Chapter 38 Frequency and count data", " Chapter 38 Frequency and count data General explanation "],["chi-squared-goodness-of-fit.html", "Chapter 39 Chi-squared goodness of fit", " Chapter 39 Chi-squared goodness of fit Explain what this is. "],["chi-squared-test-of-association.html", "Chapter 40 Chi-squared test of association", " Chapter 40 Chi-squared test of association More explanation "],["correlation-key-concepts.html", "Chapter 41 Correlation key concepts", " Chapter 41 Correlation key concepts "],["correlation-mathematics.html", "Chapter 42 Correlation mathematics", " Chapter 42 Correlation mathematics "],["correlation-hypothesis-testing.html", "Chapter 43 Correlation hypothesis testing", " Chapter 43 Correlation hypothesis testing "],["practical.-analysis-of-count-data-correlation-and-regression.html", "Chapter 44 Practical. Analysis of count data, correlation, and regression 44.1 Chi-Square Exercise 1 44.2 Chi-Square association Exercise 2 44.3 Correlation Exercise 3 44.4 Correlation Exercise 4", " Chapter 44 Practical. Analysis of count data, correlation, and regression 44.1 Chi-Square Exercise 1 44.2 Chi-Square association Exercise 2 44.3 Correlation Exercise 3 44.4 Correlation Exercise 4 "],["week-10-overview.html", "Week 10 Overview", " Week 10 Overview Week: 10 Dates: Suggested Readings: Textbook Assessments: Practice quiz Practical: "],["regression-key-concepts.html", "Chapter 45 Regression key concepts", " Chapter 45 Regression key concepts "],["regression-validity.html", "Chapter 46 Regression validity", " Chapter 46 Regression validity "],["introduction-to-multiple-regression.html", "Chapter 47 Introduction to multiple regression", " Chapter 47 Introduction to multiple regression General explanation "],["model-selection-maybe-remove-this.html", "Chapter 48 Model selection (maybe remove this?)", " Chapter 48 Model selection (maybe remove this?) Seriously consider moving the regression into this week. and ease the amount of material in previous weeks. "],["practical.-using-regression.html", "Chapter 49 Practical. Using regression 49.1 Regression Exercise 1 49.2 Regression Exercise 2 49.3 Regression Exercise 3 49.4 Regression Exercise 4", " Chapter 49 Practical. Using regression 49.1 Regression Exercise 1 49.2 Regression Exercise 2 49.3 Regression Exercise 3 49.4 Regression Exercise 4 "],["week-11-overview.html", "Week 11 Overview", " Week 11 Overview The aim of this lecture is to introduce the randomisation approach to statistical hypothesis testing. We will first introduce the general idea of what randomisation is and how it relates to the hypothesis testing that we have been doing since week five. We will then consider an instructive example in which a randomisation approach is used in place of a traditional t-test to test whether or not the mean values of two different groups are identical. We will then compare the assumptions underlying randomisation and how they differ slightly from the assumptions of traditional hypothesis testing. We will then look at how randomisation can be used to build confidence intervals and test hypotheses that would difficult to test with other approaches. In learning about randomisation approaches, we will also review some key concepts from earlier in the module. The aim is not to understand all of the nuances of randomisation, but to understand, conceptually, what is going on in the methods described below. Week: 11 Dates: Suggested Readings: Textbook Assessments: Practice quiz Practical: R starts creeping in now? "],["introduction-to-randomisation.html", "Chapter 50 Introduction to randomisation", " Chapter 50 Introduction to randomisation General explanation "],["assumptions-of-randomisation.html", "Chapter 51 Assumptions of randomisation", " Chapter 51 Assumptions of randomisation How these differ "],["bootstrapping.html", "Chapter 52 Bootstrapping", " Chapter 52 Bootstrapping What this is and why we use it. "],["monte-carlo.html", "Chapter 53 Monte Carlo", " Chapter 53 Monte Carlo "],["practical.-using-r.html", "Chapter 54 Practical. Using R 54.1 R Exercise 1 54.2 R Exercise 2 54.3 R Exercise 3", " Chapter 54 Practical. Using R 54.1 R Exercise 1 54.2 R Exercise 2 54.3 R Exercise 3 "],["week-12-overview.html", "Week 12 Overview", " Week 12 Overview Week: 12 Dates: Suggested Readings: Textbook Assessments: Practice quiz Practical: R starts creeping in now? "],["reporting-statistics.html", "Chapter 55 Reporting statistics", " Chapter 55 Reporting statistics General explanation "],["more-introduction-to-r.html", "Chapter 56 More introduction to R", " Chapter 56 More introduction to R How these differ "],["more-getting-started-with-r.html", "Chapter 57 More getting started with R", " Chapter 57 More getting started with R Just more to do. "],["practical.-using-r-1.html", "Chapter 58 Practical. Using R 58.1 R Exercise 1 58.2 R Exercise 2 58.3 R Exercise 3", " Chapter 58 Practical. Using R 58.1 R Exercise 1 58.2 R Exercise 2 58.3 R Exercise 3 "],["module-summary.html", "Module summary", " Module summary This chapter will be specifically to prepare for exam. "],["appendixA_units.html", "A Statistical units", " A Statistical units "],["uncertainty_derivation.html", "B Uncertainty derivation", " B Uncertainty derivation It is not necessary to be able to derive the equations for propagating error from week 2, but working through the below might be interesting, and provide a better appreciation for why these formulas make sense. Another derivation is available in Box, Hunter, and S (1978) (page 563), but this derivation is expressed in terms of variances and covariances, which is likely to be less helpful for this module. Propagation of error for addition and subtraction. For adding and subtracting error, we know that we get our variable \\(Z\\) by adding \\(X\\) and \\(Y\\). This is just how \\(Z\\) is defined. We also know that \\(Z\\) is going to have some error \\(E_Z\\), and we know that \\(Z\\) plus or minus its error will equal \\(X\\) plus or minus its error plus \\(Y\\) plus or minus its error, \\[(Z \\pm E_Z) = (X \\pm E_X) + (Y \\pm E_Y).\\] Again, this is just our starting definition, but double-check to make sure it makes sense. We can now note that we know, \\[Z =X+Y.\\] If it is not intuitive as to why, just imagine that there is no error associated with the measurement of \\(X\\) an \\(Y\\) (i.e., \\(E_{X} = 0\\) and \\(E_{Y} = 0\\)). In this case, there cannot be any error in \\(Z\\). So, if we substitute \\(X + Y\\) for \\(Z\\), we have the below, \\[((X + Y) \\pm E_Z) = (X \\pm E_X) + (Y \\pm E_Y).\\] By the associative property, we can get rid of the parenthesis for addition and subtraction, giving us the below, \\[X + Y \\pm E_Z = X \\pm E_X + Y \\pm E_Y.\\] Now we can subtract \\(X\\) and \\(Y\\) from both sides and see that we just have the errors of \\(X\\), \\(Y\\), and \\(Z\\), \\[\\pm E_Z = \\pm E_X \\pm E_Y.\\] The plus/minus is a bother. Note, however, that for any real number \\(m\\), \\(m^{2} = (-m)^2\\). For example, if \\(m = 4\\), then \\((4)2 = 16\\) and \\((-4)2 = 16\\), so we can square both sides to get positive numbers and make things easier, \\[E_Z^2 = (\\pm E_X \\pm E_Y)^2.\\] We can expand the above, \\[E_Z^2 = E_X^2 + E_Y^2 \\pm2E_X E_Y.\\] Now here is an assumption that we have not told you about elsewhere in the module. With the formulas that we have given you, we are assuming that the errors of \\(X\\) and \\(Y\\) are independent. To put it in more statistical terms, the covariance between the errors of \\(X\\) and \\(Y\\) is assumed to be zero. Without going into the details (covariance will be introduced later in the module), if we assume that the covariance between these errors is zero, then we can also assume the last term of the above is zero, so we can get rid of it (i.e., \\(2E_{X}E_{Y} = 0\\)), \\[E_Z^2 = E_X^2 + E_Y^2.\\] If we take the square root of both sides, then we have the equation from Chapter 7, \\[E_Z = \\sqrt{E_X^2 + E_Y^2}.\\] Propagation of error for multiplication and division. Now that we have seen the logic for propagating errors in addition and subtraction, we can do the same for multiplication and division. We can start with the same point that we are getting our new variable \\(Z\\) by multiplying \\(X\\) and \\(Y\\) together, \\(Z = XY\\). So, if both \\(X\\) and \\(Y\\) have errors, the errors will be multiplicative as below, \\[Z \\pm E_Z = (X \\pm E_X)(Y \\pm E_Y).\\] Again, all we are doing here is substituting \\(Z\\), \\(X\\), and \\(Y\\), for an expression in parentheses that includes the variable plus or minus its associated error. Now we can expand the right hand side of the equation, \\[Z \\pm E_Z = XY + Y E_X + X E_Y + E_X E_Y.\\] As with our propagation of error in addition, here we are also going to assume that the sources of error for \\(X\\) and \\(Y\\) are independent (i.e., their covariance is zero). This allows us to set \\(E_{X}E_{Y} = 0\\), which leaves us with the below, \\[Z \\pm E_Z = XY + Y E_X + X E_Y.\\] Now, because \\(Z = XY\\), we can substitute on the left hand side of the equation, \\[XY \\pm E_Z = XY + Y E_X + X E_Y.\\] Now we can subtract the \\(XY\\) from both sides of the equation, \\[\\pm E_Z = Y E_X + X E_Y.\\] Next, let us divide both sides by \\(XY\\), \\[\\frac{\\pm E_Z}{XY} = \\frac{Y E_X + X E_Y}{XY}.\\] We can expand the right hand side, \\[\\frac{\\pm E_Z}{XY} = \\frac{Y E_X}{XY} +\\frac{X E_Y}{XY}.\\] This allows us to cancel out the \\(Y\\) variables in the first term of the right hand side, and the \\(X\\) variables in second term of the right hand side, \\[\\frac{\\pm E_Z}{XY} = \\frac{E_X}{X} +\\frac{E_Y}{Y}.\\] Again, we have the plus/minus on the left, so let us square both sides, \\[\\left(\\frac{\\pm E_Z}{XY}\\right)^2 = \\left(\\frac{E_X}{X} +\\frac{E_Y}{Y}\\right)^2.\\] We can expand the right hand side, \\[\\left(\\frac{\\pm E_Z}{XY}\\right)^2 = \\left(\\frac{E_X}{X}\\right)^2 +\\left(\\frac{E_Y}{Y}\\right)^2 + 2\\left(\\frac{E_X}{X}\\right)\\left(\\frac{E_Y}{Y}\\right).\\] Again, because we are assuming that the errors of \\(X\\) and \\(Y\\) are independent, we can set the third term on the right hand side of the equation to zero. This leaves, \\[\\left(\\frac{\\pm E_Z}{XY}\\right)^2 = \\left(\\frac{E_X}{X}\\right)^2 +\\left(\\frac{E_Y}{Y}\\right)^2.\\] Note that \\(XY = Z\\), so we can substitute in the left hand side, \\[\\left(\\frac{\\pm E_Z}{Z}\\right)^2 = \\left(\\frac{E_X}{X}\\right)^2 +\\left(\\frac{E_Y}{Y}\\right)^2.\\] Now we can apply the square on the left hand side to the top and bottom, which gets rid of the plus/minus, \\[\\frac{E_Z^2}{Z^2} = \\left(\\frac{E_X}{X}\\right)^2 +\\left(\\frac{E_Y}{Y}\\right)^2.\\] We can now multiply both sides of the equation by \\(Z^2\\), \\[E_Z^2 = Z^2 \\left(\\left(\\frac{E_X}{X}\\right)^2 +\\left(\\frac{E_Y}{Y}\\right)^2 \\right).\\] We can now take the square root of both sides, \\[E_Z = \\sqrt{ Z^2 \\left( \\left( \\frac{E_X}{X}\\right)^2 + \\left(\\frac{E_Y}{Y}\\right)^2 \\right) }.\\] We can pull the \\(Z^2\\) out of the square root, \\[E_Z = Z \\sqrt{\\left( \\frac{E_X}{X}\\right)^2 + \\left(\\frac{E_Y}{Y}\\right)^2}.\\] That leaves us with the equation that was given in Chapter 7. References "],["appendixC_tables.html", "C Statistical tables", " C Statistical tables "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
